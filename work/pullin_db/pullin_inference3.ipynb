{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import os\n",
    "import warnings\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from abc import ABC\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from transformers import BertForTokenClassification, BertConfig, Adafactor, AdamW\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import label_ranking_average_precision_score, average_precision_score, f1_score\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from datasets import load_from_disk\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in\n",
    "                self.encodings.items()}  # keys are input_ids, token_type_ids, attention_mask, labels, values are stored as a list of lists\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n",
    "\n",
    "\n",
    "class newDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.encodings = {\"input_ids\": dataframe[\"input_ids\"], \"token_type_ids\": dataframe[\"token_type_ids\"],\n",
    "                          \"attention_mask\": dataframe[\"attention_mask\"]}\n",
    "        self.labels = {\"labels\": dataframe[\"labels\"]}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\"input_ids\": self.encodings[\"input_ids\"][idx], \"token_type_ids\": self.encodings[\"token_type_ids\"][idx],\n",
    "                \"attention_mask\": self.encodings[\"attention_mask\"][idx], \"labels\": self.labels[\"labels\"][idx]}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels[\"labels\"]))\n",
    "\n",
    "class BertTokClassification(pl.LightningModule, ABC):\n",
    "    def __init__(\n",
    "            self,\n",
    "            config: BertConfig = None,\n",
    "            pretrained_dir: str = None,\n",
    "            use_adafactor: bool = False,\n",
    "            learning_rate=3e-5,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.use_adafactor = use_adafactor\n",
    "        if pretrained_dir is None:\n",
    "            self.bert = BertForTokenClassification(config, **kwargs)\n",
    "        else:\n",
    "            self.bert = BertForTokenClassification.from_pretrained(pretrained_dir, **kwargs)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        return self.bert(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        outputs = self(input_ids=input_ids.to(self.device), attention_mask=attention_mask.to(self.device), labels=labels.to(self.device, dtype=torch.int64))\n",
    "        loss = outputs.loss\n",
    "\n",
    "\n",
    "        def get_acc(labels, logits):\n",
    "            sumList = []\n",
    "            for i in range(len(labels)):\n",
    "                y_pred = torch.max(logits[i], 1).indices\n",
    "                score = accuracy_score(labels[i], y_pred)\n",
    "                sumList.append(score)\n",
    "            avg = sum(sumList) / len(labels)\n",
    "            return avg\n",
    "\n",
    "\n",
    "        accuracy1 = get_acc(labels.cpu(), outputs.logits.cpu())\n",
    "\n",
    "        # accuracy = balanced_accuracy_score(master[0], master[1])\n",
    "        self.log(\n",
    "            \"train_batch_accuracy\",\n",
    "            accuracy1,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        outputs = self(input_ids=input_ids.to(self.device), attention_mask=attention_mask.to(self.device), labels=labels.to(self.device, dtype=torch.int64))\n",
    "        loss = outputs.loss\n",
    "        self.log(\n",
    "            \"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "        # def get_balanced_accuracy(labels, logits):\n",
    "        #     y_pred = torch.max(logits, 1).indices\n",
    "        #     score = balanced_accuracy_score(labels, y_pred)\n",
    "        #     return score\n",
    "        #\n",
    "        # def label_average_precision(labels, logits):\n",
    "        #     y_pred = torch.max(prob, 1).indices\n",
    "        #     score = label_ranking_average_precision_score(labels, y_pred)\n",
    "        #     return score\n",
    "        # def f1_calc(labels, logits):\n",
    "        #     sumList = []\n",
    "        #     for i in range(len(labels)):\n",
    "        #         y_pred = torch.max(logits[i], 1).indices\n",
    "        #         score = f1_score(labels[i], y_pred, average='macro')\n",
    "        #         sumList.append(score)\n",
    "        #     avg = sum(sumList) / len(labels)\n",
    "        #     return avg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # \"\"\"\n",
    "        # 1. Iterate over the batch:\n",
    "        #     for each_label in labels.cpu():\n",
    "        #         shorten the length of the list to its true length using attention list and the function [true_length]\n",
    "        #\n",
    "        #     for each_logit in outputs.logits.cpu():\n",
    "        #         use torch.max(outputs.logits.cpu()[0], 1) to get the indices for each logit (best label prediction)\n",
    "        #         shorten the indices to its proper label length\n",
    "        #         compare the indices to the labels\n",
    "        # \"\"\"\n",
    "        def true_length(y_attention_mask):  # finds the start and stop of the actual sequence\n",
    "            switch = False\n",
    "            start = 0\n",
    "            stop = 0\n",
    "            counter = 0\n",
    "            attention_mask = list(y_attention_mask)\n",
    "            for i in attention_mask:\n",
    "                if int(i) == 1 and switch == False:\n",
    "                    switch = True\n",
    "                    start = counter\n",
    "                elif int(i) == 0 and switch == True:\n",
    "                    stop = counter\n",
    "                    break\n",
    "                elif counter == 511:\n",
    "                    stop = 512\n",
    "                counter += 1\n",
    "            return (start, stop)\n",
    "\n",
    "\n",
    "        def short_clean(attention_mask, labels, logits): #attention_mask, labels.cpu(), outputs.logits.cpu()\n",
    "\n",
    "            def true_length(y_attention_mask):  # finds the start and stop of the actual sequence\n",
    "                switch = False\n",
    "                start = 0\n",
    "                stop = 0\n",
    "                counter = 0\n",
    "                attention_mask = list(y_attention_mask)\n",
    "                for i in attention_mask:\n",
    "                    if int(i) == 1 and switch == False:\n",
    "                        switch = True\n",
    "                        start = counter\n",
    "                    elif int(i) == 0 and switch == True:\n",
    "                        stop = counter\n",
    "                        break\n",
    "                    counter += 1\n",
    "                return (start, stop)\n",
    "\n",
    "            masterPred = []\n",
    "            masterTrue = []\n",
    "            for batch_index in range(len(labels)):\n",
    "                real_len = true_length(attention_mask[batch_index])\n",
    "                predIndecies = torch.max(outputs.logits.cpu()[batch_index], 1).indices\n",
    "                start = real_len[0]\n",
    "                stop = real_len[1]\n",
    "                currentTrue = torch.LongTensor(labels[batch_index][start:stop])\n",
    "                currentPred = torch.LongTensor(predIndecies[start:stop])\n",
    "                if len(currentTrue) == 0:\n",
    "                    masterTrue.append(currentTrue.tolist())\n",
    "                    masterPred.append(currentPred.tolist())\n",
    "                    print(f\"CURRENT-PRED LEN: {len(currentPred)}\")\n",
    "                    print(f\"CURRENT-TRUE LEN:{len(currentTrue)}\")\n",
    "\n",
    "            return (masterTrue, masterPred)\n",
    "\n",
    "        master = short_clean(attention_mask, labels.cpu(), outputs.logits.cpu())\n",
    "        print(\"###################################\")\n",
    "        print(f\"MASTER-TRUE: {master[0]}\")\n",
    "        print(\"###################################\")\n",
    "        print(f\"MASTER-PRED: {master[1]}\")\n",
    "        print(\"###################################\")\n",
    "        print(\"=======\")\n",
    "        print(f\"LABEL LEN: {len(labels.cpu())}\")\n",
    "        for i in range(len(labels.cpu())):\n",
    "            print(f\"SINGLE LABEL LEN: {len(labels.cpu()[i])}\")\n",
    "            print(f\"ATTENTION LEN: {len(attention_mask[i])}\")\n",
    "            #print(attention_mask[i])\n",
    "            print(f\"TRUE LEN: {true_length(attention_mask[i])}\")\n",
    "        print(\"=======\")\n",
    "        print(f\"LABELS: {labels.cpu()}\")\n",
    "        print(\"||||||||||||||||||||||||||||\")\n",
    "        print(\"=======\")\n",
    "        print(f\"LOGITS LEN: {len(outputs.logits.cpu())}\")\n",
    "        for i in outputs.logits.cpu():\n",
    "            print(f\"SINGLE LOGIT LEN: {len(i)}\")\n",
    "        print(f\"LOGIT SINGLE LIST LEN: {len(outputs.logits.cpu()[0][0])}\")\n",
    "        b_logit = torch.max(outputs.logits.cpu()[0], 1)\n",
    "        b_logit_indices = torch.max(outputs.logits.cpu()[0], 1).indices\n",
    "        print(f\"LOGIT BEST: {b_logit}\")\n",
    "        print(f\"LOGIT BEST INDICES: {b_logit_indices}\")\n",
    "        print(\"=======\")\n",
    "        print(f\"LOGITS: {outputs.logits.cpu()}\")\n",
    "\n",
    "        # accuracy = label_average_precision(labels.cpu(), logits=outputs.logits.cpu()) #replaced get_balanced_accuracy(labels.cpu(), logits=outputs.logits.cpu()) with label ranking average precision\n",
    "\n",
    "        # def balanced_accuracy_score(labels, logits):\n",
    "        #     sumList = []\n",
    "        #     for i in range(len(labels)):\n",
    "        #         y_predList = []\n",
    "        #         trueList = []\n",
    "        #         y_pred = logits[i]\n",
    "        #         previous = 0\n",
    "        #         for lab in labels[i]:\n",
    "        #             if lab == -100:\n",
    "        #                 y_predList.append(y_pred[previous])\n",
    "        #                 trueList.append(previous)\n",
    "        #             else:\n",
    "        #                 previous = lab\n",
    "        #                 y_predList.append(y_pred[previous])\n",
    "        #                 trueList.append(previous)\n",
    "        #\n",
    "        #         num = average_precision_score(trueList, y_predList)\n",
    "        #         sumList.append(num)\n",
    "        #     big = sum(sumList) / len(labels)\n",
    "        #     return big\n",
    "\n",
    "        def get_bal_acc(labels, logits):\n",
    "            sumList = []\n",
    "            for i in range(len(labels)):\n",
    "                y_pred = torch.max(logits[i], 1).indices\n",
    "                score = balanced_accuracy_score(labels[i], y_pred)\n",
    "                sumList.append(score)\n",
    "            avg = sum(sumList) / len(labels)\n",
    "            return avg\n",
    "\n",
    "        accuracy = get_bal_acc(labels.cpu(), outputs.logits.cpu())\n",
    "\n",
    "        self.log(\n",
    "            \"val_accuracy\",\n",
    "            accuracy,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.use_adafactor:\n",
    "            return Adafactor(\n",
    "                self.parameters(),\n",
    "                lr=self.learning_rate,\n",
    "                eps=(1e-30, 1e-3),\n",
    "                clip_threshold=1.0,\n",
    "                decay_rate=-0.8,\n",
    "                beta1=None,\n",
    "                weight_decay=0.0,\n",
    "                relative_step=False,\n",
    "                scale_parameter=False,\n",
    "                warmup_init=False)\n",
    "        else:\n",
    "            return AdamW(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def save_pretrained(self, pretrained_dir):\n",
    "        self.bert.save_pretrained(self, prtrained_dir)\n",
    "\n",
    "    def predict_classes(self, input_ids, attention_mask, return_logits=False):\n",
    "        output = self.bert(input_ids=input_ids.to(self.device), attention_mask=attention_mask)\n",
    "        if return_logits:\n",
    "            return output.logits\n",
    "        else:\n",
    "            probabilities = F.sigmoid(output.logits)\n",
    "            predictions = torch.argmax(probabilities)\n",
    "            return {\"probabilities\": probabilities, \"predictions\": predictions}\n",
    "\n",
    "    def get_attention(self, input_ids, attention_mask, specific_attention_head: int = None):\n",
    "        output = self.bert(inputs_ids=input_ids.to(self.device), attention_mask=attention_mask)\n",
    "        if specific_attention_head is not None:\n",
    "            last_layer = output.attentions[-1]  # grabs the last layer\n",
    "            all_last_attention_heads = [torch.max(this_input[specific_attention_head], axis=0)[0].indices for this_input in last_layer]\n",
    "            return all_last_attention_heads\n",
    "        return output.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'sequence', 'labels', 'start', 'stop'], dtype='object')\n",
      "Index(['sequence', 'labels', 'start', 'stop'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "gpu_idx = 0\n",
    "num_labels = 60\n",
    "\n",
    "#model to evaluate with\n",
    "model_path = \"/mnt/storage/grid/home/eric/hmm2bert/models/pullin/pullin>1000_whiteSpace_best_loss-epch9{1GPU}.pt\"\n",
    "#encoded csv to use\n",
    "data_folder = \"pullin_parsed_data\"\n",
    "encoded_label_filename = \"encoded_parsed_pullin_noDupes_whiteSpace>1000_withAA_not_domain.csv\"\n",
    "encoded_csv = f\"/mnt/storage/grid/home/eric/hmm2bert/{data_folder}/{encoded_label_filename}\"\n",
    "####################################################\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "#load in tokenizer, model (eval mode) and pipeline\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "model = torch.load(model_path)\n",
    "model.eval()\n",
    "meatpipe = pipeline(task='ner', model=model.bert, tokenizer=tokenizer, device=gpu_idx)\n",
    "\n",
    "# load csv to pandas dataframe\n",
    "df = pd.read_csv(encoded_csv)\n",
    "print(df.columns)\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "print(df.columns)\n",
    "\n",
    "#split the dataset into train and test, this produces a list with the row positions\n",
    "strat_train, strat_test = train_test_split(df, test_size=.2, stratify=df['labels'], random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#start count @ 0\n",
    "def labelLabel(label, sequence, start, stop):\n",
    "    sequence = sequence.split()\n",
    "    sequence = \"\".join(sequence)\n",
    "    domainList = list(range(start, stop + 1))\n",
    "    sequenceIndexCounter = 0\n",
    "    trueList = []\n",
    "\n",
    "    for currentNum in range(len(sequence)):  # iterate over each amino acid in a single sequence\n",
    "        # ====\n",
    "        shiftedNum = currentNum  #CHANGED FROM currentNum+1 TO currentNum # index that we compare to as sequence index starts at zero but start/stop starts at 1\n",
    "        # ====\n",
    "        if shiftedNum == domainList[sequenceIndexCounter]:\n",
    "            trueList.append(label)\n",
    "            if domainList[sequenceIndexCounter] == domainList[-1]:\n",
    "                    sequenceIndexCounter = 0\n",
    "\n",
    "            else:\n",
    "                sequenceIndexCounter += 1\n",
    "        else:\n",
    "            trueList.append(0)\n",
    "    return trueList\n",
    "\n",
    "def domainAcc(true_label, predict):  # finds the start and stop of the actual sequence (range style where stop is actually stop - 1)\n",
    "    switch = False\n",
    "    start = None\n",
    "    stop = len(true_label)\n",
    "    counter = 0 #CHANGED FROM 1 TO 0\n",
    "    domainLabel = None\n",
    "    numCorrectLabels = 0\n",
    "    numNotLabels = 0\n",
    "    fullDomainCounter = 0\n",
    "    \n",
    "    #gets accuracy of prediction of whole sequence\n",
    "    for i in range(len(true_label)):\n",
    "        if true_label[i] == predict[i]:\n",
    "            fullDomainCounter += 1\n",
    "    fullDomainScore = fullDomainCounter/len(predict)\n",
    "\n",
    "    #sets the start and stop of domain based on true label list\n",
    "    for i in true_label:\n",
    "        if int(i) != 0 and switch == False:\n",
    "            switch = True\n",
    "            start = counter\n",
    "        elif int(i) == 0 and switch == True:\n",
    "            stop = counter - 1\n",
    "            break\n",
    "        counter += 1\n",
    "    \n",
    "    #if domain is out of range and whole sequence is notDomain set start equal to stop + 1\n",
    "    if start == None:\n",
    "        start = stop + 1\n",
    "    \n",
    "    #calculates the number of amino acids in domain\n",
    "    numInDomain = stop - (start)\n",
    "\n",
    "    for i in true_label:\n",
    "        if i != 0:\n",
    "            domainLabel = i\n",
    "\n",
    "    for i in predict[start - 1:stop]:\n",
    "        if i == domainLabel:\n",
    "            numCorrectLabels += 1\n",
    "    try:\n",
    "        domainLabelAcc = numCorrectLabels / numInDomain\n",
    "    except:\n",
    "        domainLabelAcc = 0\n",
    "        \n",
    "    for i in predict[:start - 1]:\n",
    "        if i == 0:\n",
    "            numNotLabels += 1\n",
    "\n",
    "    for i in predict[stop - 1:]:\n",
    "        if i == 0:\n",
    "            numNotLabels += 1\n",
    "\n",
    "    numNotInDomain = len(true_label) - numInDomain\n",
    "    try:\n",
    "        notDomainLabelAcc = numNotLabels / numNotInDomain\n",
    "    except:\n",
    "        notDomainLabelAcc = 0 #numNotLabels / len(true_label) #maybe change to 0?\n",
    "\n",
    "    return [start, stop, domainLabelAcc, notDomainLabelAcc, fullDomainScore]\n",
    "\n",
    "def matching_labels(true, predict, domainStart, domainStop):\n",
    "    trueList = []\n",
    "    predictListDomain = []\n",
    "    predictListNotdomain = []\n",
    "    for label in true:\n",
    "        trueList.append(label)\n",
    "\n",
    "    for label in predict[domainStart:domainStop]:\n",
    "        predictListDomain.append(label)\n",
    "\n",
    "    for label in predict[:domainStart + 1]:\n",
    "        predictListNotdomain.append(label)\n",
    "    for label in predict[domainStop:]:\n",
    "        predictListNotdomain.append(label)\n",
    "\n",
    "    trueList = set(trueList)\n",
    "    trueList = list(trueList)\n",
    "    predictListDomain = set(predictListDomain)\n",
    "    predictListDomain = list(predictListDomain)\n",
    "    predictListNotdomain = set(predictListNotdomain)\n",
    "    predictListNotdomain = list(predictListNotdomain)\n",
    "\n",
    "    return (trueList, predictListDomain, predictListNotdomain)\n",
    "\n",
    "def evaluate_positions(true, predict):\n",
    "    switch1 = True\n",
    "    switch2 = True\n",
    "    predStart = None\n",
    "    trueStart = None\n",
    "    predStop = None\n",
    "    trueStop = None\n",
    "    counter = 0\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(true)):\n",
    "\n",
    "        if true[i] != 0 and switch2:\n",
    "            switch2 = False\n",
    "            trueStart = i\n",
    "#                 print(f\"REAL START POSITION {trueStart}\")\n",
    "\n",
    "        if predict[i] != 0 and switch1:\n",
    "            switch1 = False\n",
    "            predStart = i\n",
    "#                 print(f\"PRED START POSITION {predStart}\")\n",
    "\n",
    "        if true[i] == 0 and switch2 == False:\n",
    "            switch2 = None\n",
    "            trueStop = i - 1\n",
    "#                 print(f\"REAL STOP POSITION {trueStop}\")\n",
    "\n",
    "        if predict[i] == 0 and switch1 == False:\n",
    "            switch1 = None\n",
    "            predStop = i - 1\n",
    "#                 print(f\"PRED STOP POSITION {predStop}\")\n",
    "\n",
    "#             if predict[i] != true[i]:\n",
    "#                 print(f\"{counter}) {true[i]}|=|{predict[i]} >> NOT\")\n",
    "#             else:\n",
    "#                 print(f\"{counter}) {true[i]}|=|{predict[i]}\")\n",
    "        counter += 1\n",
    "\n",
    "    if switch2 == False and trueStop == None:\n",
    "        trueStop = len(true)\n",
    "\n",
    "    if switch1 == False and predStop == None:\n",
    "        predStop = len(predict)\n",
    "\n",
    "    if trueStart == None and switch2 == True:\n",
    "        print(\"HAAAAAAAAAAAAAAAAAAA NO DOMAIN\")\n",
    "        print(trueStart, trueStop, predStart, predStop)\n",
    "\n",
    "    return (trueStart, trueStop, predStart, predStop)\n",
    "#==================================\n",
    "def metric_extractor(strat_test):\n",
    "    \n",
    "    #parses through each sample and adds metrics to dict which is then appended to a list\n",
    "    masterList = []\n",
    "    sampleCounter = 0\n",
    "\n",
    "    for i in range(len(strat_test)):\n",
    "        labelDict = {}\n",
    "        sampleDict = {}\n",
    "        pred_labels = []\n",
    "        tempList = meatpipe(strat_test.iloc[i][\"sequence\"], max_length=512)\n",
    "        label = strat_test.iloc[i][\"labels\"]\n",
    "        sequence = strat_test.iloc[i][\"sequence\"]\n",
    "        start = strat_test.iloc[i][\"start\"]\n",
    "        stop = strat_test.iloc[i][\"stop\"]\n",
    "        true_labels = labelLabel(label, sequence, start, stop)\n",
    "\n",
    "\n",
    "        for aminoDict in tempList:\n",
    "            labelNum = aminoDict[\"entity\"]\n",
    "            labelNum = int(labelNum[6:])\n",
    "            pred_labels.append(labelNum)\n",
    "\n",
    "        positions = evaluate_positions(true_labels, pred_labels)\n",
    "        trueStart = positions[0]\n",
    "        trueStop = positions[1]\n",
    "        predStart = positions[2]\n",
    "        predStop = positions[3]\n",
    "\n",
    "        eval_metrics = domainAcc(true_labels, pred_labels)\n",
    "        eval_start = eval_metrics[0]\n",
    "        eval_stop = eval_metrics[1]\n",
    "        domainLabelAcc = eval_metrics[2]\n",
    "        notDomainLabelAcc = eval_metrics[3]\n",
    "        fullDomainAcc = eval_metrics[4]\n",
    "\n",
    "        domainStart = eval_start - 1\n",
    "        domainStop = eval_stop\n",
    "\n",
    "        items = matching_labels(true_labels, pred_labels, domainStart, domainStop)\n",
    "        trueItems = items[0]\n",
    "        predDomItems = items[1]\n",
    "        predNotDomItems = items[2]\n",
    "\n",
    "        if notDomainLabelAcc < 0:\n",
    "            print(\"NEGATIVE VALUE\")\n",
    "    #         print(f\"{notDomainLabelAcc} = {eval_metrics[5]} / {eval_metrics[6]}\")\n",
    "    #         print(start, stop)\n",
    "    #         print(trueStart, trueStop)\n",
    "    #         print(label)\n",
    "\n",
    "        sampleDict[\"fullDomain_accuracy\"] = float(fullDomainAcc)\n",
    "        sampleDict[\"domain_accuracy\"] = float(domainLabelAcc)\n",
    "        sampleDict[\"notDomain_accuracy\"] = float(notDomainLabelAcc)\n",
    "        sampleDict[\"true_labels\"] = list(trueItems)\n",
    "        sampleDict[\"predDomain_labels\"] = list(predDomItems)\n",
    "        sampleDict[\"predNotDomain_labels\"] = list(predNotDomItems)\n",
    "        sampleDict[\"trueStart\"] = trueStart\n",
    "        sampleDict[\"trueStop\"] = trueStop\n",
    "        sampleDict[\"predStart\"] = float(predStart)\n",
    "        sampleDict[\"predStop\"] = float(predStop)\n",
    "\n",
    "\n",
    "        for i in trueItems:\n",
    "            if i != 0:\n",
    "                attentionLabel = str(i)\n",
    "\n",
    "\n",
    "        labelDict[attentionLabel] = sampleDict\n",
    "\n",
    "        masterList.append(labelDict)\n",
    "\n",
    "        sampleCounter += 1\n",
    "        if sampleCounter % 100 == 0:\n",
    "            print(f\"{sampleCounter} / {len(strat_test)}\")\n",
    "    #     print(sampleDict)\n",
    "    #     print(\"=============================\")\n",
    "    return masterList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAAAAAAAAAAAAAAAAAAA NO DOMAIN\n",
      "None None 0 18\n",
      "100 / 96420\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-a7599d92e46e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmasterList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrat_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-d6c4bbd93b88>\u001b[0m in \u001b[0;36mmetric_extractor\u001b[0;34m(strat_test_path)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0msampleDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mtempList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeatpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrat_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sequence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrat_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrat_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sequence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/transformers/pipelines/token_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m             filtered_labels_idx = [\n\u001b[1;32m    186\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspecial_tokens_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             ]\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/transformers/pipelines/token_classification.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspecial_tokens_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             ]\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "masterList = metric_extractor(strat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'int64' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-f307984c530c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfinalZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmasterList\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/mnt/storage/grid/home/eric/hmm2bert/pullin_parsed_data/pullin>1000_TESTING\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinalZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'int64' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "finalZ = {\"0\": masterList}\n",
    "with open(\"/mnt/storage/grid/home/eric/hmm2bert/pullin_parsed_data/pullin>1000_TESTING\", \"w\") as file:\n",
    "    json.dump(finalZ, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'2': {'fullDomain_accuracy': 0.41479099678456594,\n",
       "   'domain_accuracy': 0.4155405405405405,\n",
       "   'notDomain_accuracy': 0.6,\n",
       "   'true_labels': [0, 2],\n",
       "   'predDomain_labels': [0, 2],\n",
       "   'predNotDomain_labels': [0, 2],\n",
       "   'trueStart': 7.0,\n",
       "   'trueStop': 303.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 112.0}},\n",
       " {'58': {'fullDomain_accuracy': 0.6911764705882353,\n",
       "   'domain_accuracy': 0.21875,\n",
       "   'notDomain_accuracy': 0.8115942028985508,\n",
       "   'true_labels': [0, 58],\n",
       "   'predDomain_labels': [0, 58],\n",
       "   'predNotDomain_labels': [0, 25, 58, 5],\n",
       "   'trueStart': 259.0,\n",
       "   'trueStop': 323.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 0.0}},\n",
       " {'5': {'fullDomain_accuracy': 0.474609375,\n",
       "   'domain_accuracy': 0.375,\n",
       "   'notDomain_accuracy': 0.825,\n",
       "   'true_labels': [0, 5],\n",
       "   'predDomain_labels': [0, 5],\n",
       "   'predNotDomain_labels': [0, 58, 5],\n",
       "   'trueStart': 19.0,\n",
       "   'trueStop': 411.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 104.0}},\n",
       " {'17': {'fullDomain_accuracy': 0.25,\n",
       "   'domain_accuracy': 0.28227571115973743,\n",
       "   'notDomain_accuracy': 0.01818181818181818,\n",
       "   'true_labels': [0, 17],\n",
       "   'predDomain_labels': [0, 17],\n",
       "   'predNotDomain_labels': [17],\n",
       "   'trueStart': 55.0,\n",
       "   'trueStop': 512.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 134.0}},\n",
       " {'33': {'fullDomain_accuracy': 0.3359375,\n",
       "   'domain_accuracy': 0.2752941176470588,\n",
       "   'notDomain_accuracy': 0.6666666666666666,\n",
       "   'true_labels': [0, 33],\n",
       "   'predDomain_labels': [0, 33],\n",
       "   'predNotDomain_labels': [0, 33],\n",
       "   'trueStart': 36.0,\n",
       "   'trueStop': 461.0,\n",
       "   'predStart': 4.0,\n",
       "   'predStop': 4.0}},\n",
       " {'48': {'fullDomain_accuracy': 0.2736318407960199,\n",
       "   'domain_accuracy': 0.41818181818181815,\n",
       "   'notDomain_accuracy': 0.13186813186813187,\n",
       "   'true_labels': [0, 48],\n",
       "   'predDomain_labels': [48, 0],\n",
       "   'predNotDomain_labels': [48, 0],\n",
       "   'trueStart': 80.0,\n",
       "   'trueStop': 190.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 112.0}},\n",
       " {'5': {'fullDomain_accuracy': 0.439453125,\n",
       "   'domain_accuracy': 0.32019704433497537,\n",
       "   'notDomain_accuracy': 0.9245283018867925,\n",
       "   'true_labels': [0, 5],\n",
       "   'predDomain_labels': [0, 58, 5],\n",
       "   'predNotDomain_labels': [0, 5],\n",
       "   'trueStart': 10.0,\n",
       "   'trueStop': 416.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 2.0}},\n",
       " {'26': {'fullDomain_accuracy': 0.3157894736842105,\n",
       "   'domain_accuracy': 0.3207070707070707,\n",
       "   'notDomain_accuracy': 0.6666666666666666,\n",
       "   'true_labels': [0, 26],\n",
       "   'predDomain_labels': [0, 26],\n",
       "   'predNotDomain_labels': [0, 26],\n",
       "   'trueStart': 1.0,\n",
       "   'trueStop': 397.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 12.0}},\n",
       " {'2': {'fullDomain_accuracy': 0.3333333333333333,\n",
       "   'domain_accuracy': 0.34146341463414637,\n",
       "   'notDomain_accuracy': 0.4,\n",
       "   'true_labels': [0, 2],\n",
       "   'predDomain_labels': [0, 2],\n",
       "   'predNotDomain_labels': [0, 2],\n",
       "   'trueStart': 7.0,\n",
       "   'trueStop': 294.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 20.0}},\n",
       " {'30': {'fullDomain_accuracy': 0.5046948356807511,\n",
       "   'domain_accuracy': 0.508235294117647,\n",
       "   'notDomain_accuracy': 1.0,\n",
       "   'true_labels': [0, 30],\n",
       "   'predDomain_labels': [0, 30],\n",
       "   'predNotDomain_labels': [30],\n",
       "   'trueStart': 1.0,\n",
       "   'trueStop': 426.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 51.0}},\n",
       " {'28': {'fullDomain_accuracy': 0.5784615384615385,\n",
       "   'domain_accuracy': 0.4419642857142857,\n",
       "   'notDomain_accuracy': 0.9108910891089109,\n",
       "   'true_labels': [0, 28],\n",
       "   'predDomain_labels': [0, 28],\n",
       "   'predNotDomain_labels': [0, 28],\n",
       "   'trueStart': 10.0,\n",
       "   'trueStop': 234.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 75.0}},\n",
       " {'33': {'fullDomain_accuracy': 0.54296875,\n",
       "   'domain_accuracy': 0.3254437869822485,\n",
       "   'notDomain_accuracy': 0.9712643678160919,\n",
       "   'true_labels': [0, 33],\n",
       "   'predDomain_labels': [0, 33, 25],\n",
       "   'predNotDomain_labels': [0, 33, 2],\n",
       "   'trueStart': 1.0,\n",
       "   'trueStop': 339.0,\n",
       "   'predStart': 1.0,\n",
       "   'predStop': 2.0}},\n",
       " {'5': {'fullDomain_accuracy': 0.62109375,\n",
       "   'domain_accuracy': 0.7590361445783133,\n",
       "   'notDomain_accuracy': 0.5578034682080925,\n",
       "   'true_labels': [0, 5],\n",
       "   'predDomain_labels': [0, 5],\n",
       "   'predNotDomain_labels': [0, 5, 23],\n",
       "   'trueStart': 346.0,\n",
       "   'trueStop': 512.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 38.0}},\n",
       " {'32': {'fullDomain_accuracy': 0.666015625,\n",
       "   'domain_accuracy': 0.39864864864864863,\n",
       "   'notDomain_accuracy': 0.7774725274725275,\n",
       "   'true_labels': [0, 32],\n",
       "   'predDomain_labels': [32, 0],\n",
       "   'predNotDomain_labels': [0, 25, 32],\n",
       "   'trueStart': 364.0,\n",
       "   'trueStop': 512.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 15.0}},\n",
       " {'40': {'fullDomain_accuracy': 0.40476190476190477,\n",
       "   'domain_accuracy': 0.37142857142857144,\n",
       "   'notDomain_accuracy': 1.0,\n",
       "   'true_labels': [0, 40],\n",
       "   'predDomain_labels': [40, 0, 53],\n",
       "   'predNotDomain_labels': [40, 0],\n",
       "   'trueStart': 1.0,\n",
       "   'trueStop': 36.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 10.0}},\n",
       " {'2': {'fullDomain_accuracy': 0.4090909090909091,\n",
       "   'domain_accuracy': 0.4013840830449827,\n",
       "   'notDomain_accuracy': 0.6842105263157895,\n",
       "   'true_labels': [0, 2],\n",
       "   'predDomain_labels': [0, 2],\n",
       "   'predNotDomain_labels': [0, 2],\n",
       "   'trueStart': 7.0,\n",
       "   'trueStop': 296.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 118.0}},\n",
       " {'17': {'fullDomain_accuracy': 0.326171875,\n",
       "   'domain_accuracy': 0.3287671232876712,\n",
       "   'notDomain_accuracy': 1.0,\n",
       "   'true_labels': [0, 17],\n",
       "   'predDomain_labels': [0, 17],\n",
       "   'predNotDomain_labels': [17],\n",
       "   'trueStart': 1.0,\n",
       "   'trueStop': 512.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 116.0}},\n",
       " {'58': {'fullDomain_accuracy': 0.5060240963855421,\n",
       "   'domain_accuracy': 0.47540983606557374,\n",
       "   'notDomain_accuracy': 0.7272727272727273,\n",
       "   'true_labels': [0, 58],\n",
       "   'predDomain_labels': [0, 58],\n",
       "   'predNotDomain_labels': [0, 58],\n",
       "   'trueStart': 7.0,\n",
       "   'trueStop': 68.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 22.0}},\n",
       " {'39': {'fullDomain_accuracy': 0.30049261083743845,\n",
       "   'domain_accuracy': 0.25268817204301075,\n",
       "   'notDomain_accuracy': 1.0,\n",
       "   'true_labels': [0, 39],\n",
       "   'predDomain_labels': [0, 39],\n",
       "   'predNotDomain_labels': [0, 39],\n",
       "   'trueStart': 1.0,\n",
       "   'trueStop': 187.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 27.0}},\n",
       " {'5': {'fullDomain_accuracy': 0.4296875,\n",
       "   'domain_accuracy': 0.3526448362720403,\n",
       "   'notDomain_accuracy': 0.7217391304347827,\n",
       "   'true_labels': [0, 5],\n",
       "   'predDomain_labels': [0, 5],\n",
       "   'predNotDomain_labels': [0, 5],\n",
       "   'trueStart': 33.0,\n",
       "   'trueStop': 430.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 100.0}},\n",
       " {'5': {'fullDomain_accuracy': 0.375,\n",
       "   'domain_accuracy': 0.3251231527093596,\n",
       "   'notDomain_accuracy': 0.5943396226415094,\n",
       "   'true_labels': [0, 5],\n",
       "   'predDomain_labels': [0, 58, 3, 5],\n",
       "   'predNotDomain_labels': [0, 3, 5],\n",
       "   'trueStart': 41.0,\n",
       "   'trueStop': 447.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 177.0}},\n",
       " {'7': {'fullDomain_accuracy': 0.15492957746478872,\n",
       "   'domain_accuracy': 0.1700507614213198,\n",
       "   'notDomain_accuracy': 0.03125,\n",
       "   'true_labels': [0, 7],\n",
       "   'predDomain_labels': [0, 7],\n",
       "   'predNotDomain_labels': [7],\n",
       "   'trueStart': 32.0,\n",
       "   'trueStop': 426.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 88.0}},\n",
       " {'58': {'fullDomain_accuracy': 0.5483870967741935,\n",
       "   'domain_accuracy': 0.5689655172413793,\n",
       "   'notDomain_accuracy': 0.6,\n",
       "   'true_labels': [0, 58],\n",
       "   'predDomain_labels': [0, 58],\n",
       "   'predNotDomain_labels': [0, 58],\n",
       "   'trueStart': 15.0,\n",
       "   'trueStop': 73.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 42.0}},\n",
       " {'19': {'fullDomain_accuracy': 0.15025906735751296,\n",
       "   'domain_accuracy': 0.1676829268292683,\n",
       "   'notDomain_accuracy': 0.10344827586206896,\n",
       "   'true_labels': [0, 19],\n",
       "   'predDomain_labels': [0, 25, 19],\n",
       "   'predNotDomain_labels': [0, 19],\n",
       "   'trueStart': 53.0,\n",
       "   'trueStop': 381.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 93.0}},\n",
       " {'4': {'fullDomain_accuracy': 0.33783783783783783,\n",
       "   'domain_accuracy': 0.34146341463414637,\n",
       "   'notDomain_accuracy': 1.0,\n",
       "   'true_labels': [0, 4],\n",
       "   'predDomain_labels': [0, 4],\n",
       "   'predNotDomain_labels': [4],\n",
       "   'trueStart': 1.0,\n",
       "   'trueStop': 370.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 75.0}},\n",
       " {'5': {'fullDomain_accuracy': 0.7265625,\n",
       "   'domain_accuracy': 0.6,\n",
       "   'notDomain_accuracy': 0.8138801261829653,\n",
       "   'true_labels': [0, 5],\n",
       "   'predDomain_labels': [0, 5],\n",
       "   'predNotDomain_labels': [0, 58, 5],\n",
       "   'trueStart': 1.0,\n",
       "   'trueStop': 196.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 94.0}},\n",
       " {'9': {'fullDomain_accuracy': 0.322265625,\n",
       "   'domain_accuracy': 0.3747178329571106,\n",
       "   'notDomain_accuracy': 0.014492753623188406,\n",
       "   'true_labels': [0, 9],\n",
       "   'predDomain_labels': [0, 9, 32],\n",
       "   'predNotDomain_labels': [9],\n",
       "   'trueStart': 69.0,\n",
       "   'trueStop': 512.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 147.0}},\n",
       " {'5': {'fullDomain_accuracy': 0.677734375,\n",
       "   'domain_accuracy': 0.6062717770034843,\n",
       "   'notDomain_accuracy': 0.7777777777777778,\n",
       "   'true_labels': [0, 5],\n",
       "   'predDomain_labels': [0, 5],\n",
       "   'predNotDomain_labels': [0, 5, 23],\n",
       "   'trueStart': 225.0,\n",
       "   'trueStop': 512.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 10.0}},\n",
       " {'5': {'fullDomain_accuracy': 0.380859375,\n",
       "   'domain_accuracy': 0.33246753246753247,\n",
       "   'notDomain_accuracy': 0.5433070866141733,\n",
       "   'true_labels': [0, 5],\n",
       "   'predDomain_labels': [0, 5],\n",
       "   'predNotDomain_labels': [0, 5],\n",
       "   'trueStart': 127.0,\n",
       "   'trueStop': 512.0,\n",
       "   'predStart': 14.0,\n",
       "   'predStop': 14.0}},\n",
       " {'33': {'fullDomain_accuracy': 0.24878048780487805,\n",
       "   'domain_accuracy': 0.2562189054726368,\n",
       "   'notDomain_accuracy': 0.125,\n",
       "   'true_labels': [0, 33],\n",
       "   'predDomain_labels': [0, 33],\n",
       "   'predNotDomain_labels': [33],\n",
       "   'trueStart': 8.0,\n",
       "   'trueStop': 410.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 76.0}},\n",
       " {'23': {'fullDomain_accuracy': 0.59765625,\n",
       "   'domain_accuracy': 0.37209302325581395,\n",
       "   'notDomain_accuracy': 0.933649289099526,\n",
       "   'true_labels': [0, 23],\n",
       "   'predDomain_labels': [0, 23],\n",
       "   'predNotDomain_labels': [0, 58, 5, 23],\n",
       "   'trueStart': 6.0,\n",
       "   'trueStop': 307.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 71.0}},\n",
       " {'58': {'fullDomain_accuracy': 0.5121951219512195,\n",
       "   'domain_accuracy': 0.5303030303030303,\n",
       "   'notDomain_accuracy': 0.625,\n",
       "   'true_labels': [0, 58],\n",
       "   'predDomain_labels': [0, 58],\n",
       "   'predNotDomain_labels': [0, 58],\n",
       "   'trueStart': 7.0,\n",
       "   'trueStop': 73.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 40.0}},\n",
       " {'5': {'fullDomain_accuracy': 0.091796875,\n",
       "   'domain_accuracy': 0.015283842794759825,\n",
       "   'notDomain_accuracy': 0.7777777777777778,\n",
       "   'true_labels': [0, 5],\n",
       "   'predDomain_labels': [0, 3, 5],\n",
       "   'predNotDomain_labels': [0, 3, 5],\n",
       "   'trueStart': 13.0,\n",
       "   'trueStop': 471.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 117.0}},\n",
       " {'5': {'fullDomain_accuracy': 0.380859375,\n",
       "   'domain_accuracy': 0.25956284153005466,\n",
       "   'notDomain_accuracy': 0.6986301369863014,\n",
       "   'true_labels': [0, 5],\n",
       "   'predDomain_labels': [0, 5],\n",
       "   'predNotDomain_labels': [0, 5],\n",
       "   'trueStart': 146.0,\n",
       "   'trueStop': 512.0,\n",
       "   'predStart': 20.0,\n",
       "   'predStop': 21.0}},\n",
       " {'23': {'fullDomain_accuracy': 0.587890625,\n",
       "   'domain_accuracy': 0.3333333333333333,\n",
       "   'notDomain_accuracy': 0.9622641509433962,\n",
       "   'true_labels': [0, 23],\n",
       "   'predDomain_labels': [0, 23],\n",
       "   'predNotDomain_labels': [0, 58, 5, 23],\n",
       "   'trueStart': 6.0,\n",
       "   'trueStop': 306.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 58.0}},\n",
       " {'23': {'fullDomain_accuracy': 0.57421875,\n",
       "   'domain_accuracy': 0.36486486486486486,\n",
       "   'notDomain_accuracy': 0.875,\n",
       "   'true_labels': [0, 23],\n",
       "   'predDomain_labels': [0, 23],\n",
       "   'predNotDomain_labels': [0, 23],\n",
       "   'trueStart': 28.0,\n",
       "   'trueStop': 324.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 84.0}},\n",
       " {'33': {'fullDomain_accuracy': 0.30078125,\n",
       "   'domain_accuracy': 0.23943661971830985,\n",
       "   'notDomain_accuracy': 0.6395348837209303,\n",
       "   'true_labels': [0, 33],\n",
       "   'predDomain_labels': [0, 33],\n",
       "   'predNotDomain_labels': [0, 33],\n",
       "   'trueStart': 43.0,\n",
       "   'trueStop': 469.0,\n",
       "   'predStart': 3.0,\n",
       "   'predStop': 3.0}},\n",
       " {'33': {'fullDomain_accuracy': 0.322265625,\n",
       "   'domain_accuracy': 0.25118483412322273,\n",
       "   'notDomain_accuracy': 0.6888888888888889,\n",
       "   'true_labels': [0, 33],\n",
       "   'predDomain_labels': [0, 33, 58],\n",
       "   'predNotDomain_labels': [0, 33],\n",
       "   'trueStart': 29.0,\n",
       "   'trueStop': 451.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 107.0}},\n",
       " {'23': {'fullDomain_accuracy': 0.587890625,\n",
       "   'domain_accuracy': 0.347682119205298,\n",
       "   'notDomain_accuracy': 0.9476190476190476,\n",
       "   'true_labels': [0, 23],\n",
       "   'predDomain_labels': [0, 23],\n",
       "   'predNotDomain_labels': [0, 5, 23],\n",
       "   'trueStart': 11.0,\n",
       "   'trueStop': 313.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 68.0}},\n",
       " {'5': {'fullDomain_accuracy': 0.51953125,\n",
       "   'domain_accuracy': 0.4244791666666667,\n",
       "   'notDomain_accuracy': 0.828125,\n",
       "   'true_labels': [0, 5],\n",
       "   'predDomain_labels': [0, 5],\n",
       "   'predNotDomain_labels': [0, 58, 5],\n",
       "   'trueStart': 22.0,\n",
       "   'trueStop': 406.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 123.0}},\n",
       " {'44': {'fullDomain_accuracy': 0.41015625,\n",
       "   'domain_accuracy': 0.44234800838574423,\n",
       "   'notDomain_accuracy': 0.02857142857142857,\n",
       "   'true_labels': [0, 44],\n",
       "   'predDomain_labels': [0, 44],\n",
       "   'predNotDomain_labels': [44],\n",
       "   'trueStart': 35.0,\n",
       "   'trueStop': 512.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 233.0}},\n",
       " {'58': {'fullDomain_accuracy': 0.4835164835164835,\n",
       "   'domain_accuracy': 0.4714285714285714,\n",
       "   'notDomain_accuracy': 0.6666666666666666,\n",
       "   'true_labels': [0, 58],\n",
       "   'predDomain_labels': [0, 58],\n",
       "   'predNotDomain_labels': [0, 58],\n",
       "   'trueStart': 8.0,\n",
       "   'trueStop': 78.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 23.0}},\n",
       " {'49': {'fullDomain_accuracy': 0.2693726937269373,\n",
       "   'domain_accuracy': 0.2740740740740741,\n",
       "   'notDomain_accuracy': 1.0,\n",
       "   'true_labels': [0, 49],\n",
       "   'predDomain_labels': [0, 49],\n",
       "   'predNotDomain_labels': [49],\n",
       "   'trueStart': 1.0,\n",
       "   'trueStop': 271.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 33.0}},\n",
       " {'56': {'fullDomain_accuracy': 0.28296703296703296,\n",
       "   'domain_accuracy': 0.1617161716171617,\n",
       "   'notDomain_accuracy': 0.9344262295081968,\n",
       "   'true_labels': [0, 56],\n",
       "   'predDomain_labels': [0, 5, 56, 25, 57],\n",
       "   'predNotDomain_labels': [56, 0],\n",
       "   'trueStart': 5.0,\n",
       "   'trueStop': 308.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 58.0}},\n",
       " {'37': {'fullDomain_accuracy': 0.228515625,\n",
       "   'domain_accuracy': 0.233201581027668,\n",
       "   'notDomain_accuracy': 0.16666666666666666,\n",
       "   'true_labels': [0, 37],\n",
       "   'predDomain_labels': [0, 25, 37],\n",
       "   'predNotDomain_labels': [37],\n",
       "   'trueStart': 6.0,\n",
       "   'trueStop': 512.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 67.0}},\n",
       " {'2': {'fullDomain_accuracy': 0.36774193548387096,\n",
       "   'domain_accuracy': 0.3745819397993311,\n",
       "   'notDomain_accuracy': 0.45454545454545453,\n",
       "   'true_labels': [0, 2],\n",
       "   'predDomain_labels': [0, 2],\n",
       "   'predNotDomain_labels': [0, 2],\n",
       "   'trueStart': 7.0,\n",
       "   'trueStop': 306.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 59.0}},\n",
       " {'33': {'fullDomain_accuracy': 0.33984375,\n",
       "   'domain_accuracy': 0.2962085308056872,\n",
       "   'notDomain_accuracy': 0.5777777777777777,\n",
       "   'true_labels': [0, 33],\n",
       "   'predDomain_labels': [0, 33],\n",
       "   'predNotDomain_labels': [0, 33],\n",
       "   'trueStart': 39.0,\n",
       "   'trueStop': 461.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 120.0}},\n",
       " {'5': {'fullDomain_accuracy': 0.6007067137809188,\n",
       "   'domain_accuracy': 0.5761589403973509,\n",
       "   'notDomain_accuracy': 0.6439393939393939,\n",
       "   'true_labels': [0, 5],\n",
       "   'predDomain_labels': [0, 5],\n",
       "   'predNotDomain_labels': [0, 5, 23],\n",
       "   'trueStart': 132.0,\n",
       "   'trueStop': 283.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 1.0}},\n",
       " {'48': {'fullDomain_accuracy': 0.2388663967611336,\n",
       "   'domain_accuracy': 0.55,\n",
       "   'notDomain_accuracy': 0.047619047619047616,\n",
       "   'true_labels': [0, 48],\n",
       "   'predDomain_labels': [48, 0],\n",
       "   'predNotDomain_labels': [48, 0],\n",
       "   'trueStart': 144.0,\n",
       "   'trueStop': 244.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 54.0}},\n",
       " {'2': {'fullDomain_accuracy': 0.75390625,\n",
       "   'domain_accuracy': 0.5179282868525896,\n",
       "   'notDomain_accuracy': 0.9923371647509579,\n",
       "   'true_labels': [0, 2],\n",
       "   'predDomain_labels': [0, 2],\n",
       "   'predNotDomain_labels': [0, 2],\n",
       "   'trueStart': 3.0,\n",
       "   'trueStop': 254.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 92.0}},\n",
       " {'55': {'fullDomain_accuracy': 0.5128865979381443,\n",
       "   'domain_accuracy': 0.5900383141762452,\n",
       "   'notDomain_accuracy': 0.3779527559055118,\n",
       "   'true_labels': [0, 55],\n",
       "   'predDomain_labels': [0, 55],\n",
       "   'predNotDomain_labels': [0, 55],\n",
       "   'trueStart': 80.0,\n",
       "   'trueStop': 341.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 216.0}},\n",
       " {'58': {'fullDomain_accuracy': 0.4659090909090909,\n",
       "   'domain_accuracy': 0.4305555555555556,\n",
       "   'notDomain_accuracy': 0.8125,\n",
       "   'true_labels': [0, 58],\n",
       "   'predDomain_labels': [0, 58],\n",
       "   'predNotDomain_labels': [0, 58],\n",
       "   'trueStart': 4.0,\n",
       "   'trueStop': 76.0,\n",
       "   'predStart': 0.0,\n",
       "   'predStop': 22.0}}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'int64' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-0b3cb51719ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasterList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/mnt/storage/grid/home/eric/hmm2bert/pullin_parsed_data/pullin>1000_TESTING\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'int64' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "s = json.dumps(masterList)\n",
    "open(\"/mnt/storage/grid/home/eric/hmm2bert/pullin_parsed_data/pullin>1000_TESTING\", \"w\").write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'list'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n",
      "<class 'str'> <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "for g in masterList:\n",
    "    for i in g:\n",
    "        print(type(g))\n",
    "        print(type(i))\n",
    "        di = g[i]\n",
    "        for title in di:\n",
    "            print(type(title), type(di[title]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "dnabert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
