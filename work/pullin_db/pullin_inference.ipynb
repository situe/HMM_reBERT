{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import os\n",
    "import warnings\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from abc import ABC\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from transformers import BertForTokenClassification, BertConfig, Adafactor, AdamW\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import label_ranking_average_precision_score, average_precision_score, f1_score\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from datasets import load_from_disk\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class TokenDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in\n",
    "                self.encodings.items()}  # keys are input_ids, token_type_ids, attention_mask, labels, values are stored as a list of lists\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n",
    "\n",
    "\n",
    "class newDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.encodings = {\"input_ids\": dataframe[\"input_ids\"], \"token_type_ids\": dataframe[\"token_type_ids\"],\n",
    "                          \"attention_mask\": dataframe[\"attention_mask\"]}\n",
    "        self.labels = {\"labels\": dataframe[\"labels\"]}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\"input_ids\": self.encodings[\"input_ids\"][idx], \"token_type_ids\": self.encodings[\"token_type_ids\"][idx],\n",
    "                \"attention_mask\": self.encodings[\"attention_mask\"][idx], \"labels\": self.labels[\"labels\"][idx]}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels[\"labels\"]))\n",
    "\n",
    "class BertTokClassification(pl.LightningModule, ABC):\n",
    "    def __init__(\n",
    "            self,\n",
    "            config: BertConfig = None,\n",
    "            pretrained_dir: str = None,\n",
    "            use_adafactor: bool = False,\n",
    "            learning_rate=3e-5,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.use_adafactor = use_adafactor\n",
    "        if pretrained_dir is None:\n",
    "            self.bert = BertForTokenClassification(config, **kwargs)\n",
    "        else:\n",
    "            self.bert = BertForTokenClassification.from_pretrained(pretrained_dir, **kwargs)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        return self.bert(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        outputs = self(input_ids=input_ids.to(self.device), attention_mask=attention_mask.to(self.device), labels=labels.to(self.device, dtype=torch.int64))\n",
    "        loss = outputs.loss\n",
    "\n",
    "\n",
    "        def get_acc(labels, logits):\n",
    "            sumList = []\n",
    "            for i in range(len(labels)):\n",
    "                y_pred = torch.max(logits[i], 1).indices\n",
    "                score = accuracy_score(labels[i], y_pred)\n",
    "                sumList.append(score)\n",
    "            avg = sum(sumList) / len(labels)\n",
    "            return avg\n",
    "\n",
    "\n",
    "        accuracy1 = get_acc(labels.cpu(), outputs.logits.cpu())\n",
    "\n",
    "        # accuracy = balanced_accuracy_score(master[0], master[1])\n",
    "        self.log(\n",
    "            \"train_batch_accuracy\",\n",
    "            accuracy1,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        outputs = self(input_ids=input_ids.to(self.device), attention_mask=attention_mask.to(self.device), labels=labels.to(self.device, dtype=torch.int64))\n",
    "        loss = outputs.loss\n",
    "        self.log(\n",
    "            \"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "        # def get_balanced_accuracy(labels, logits):\n",
    "        #     y_pred = torch.max(logits, 1).indices\n",
    "        #     score = balanced_accuracy_score(labels, y_pred)\n",
    "        #     return score\n",
    "        #\n",
    "        # def label_average_precision(labels, logits):\n",
    "        #     y_pred = torch.max(prob, 1).indices\n",
    "        #     score = label_ranking_average_precision_score(labels, y_pred)\n",
    "        #     return score\n",
    "        # def f1_calc(labels, logits):\n",
    "        #     sumList = []\n",
    "        #     for i in range(len(labels)):\n",
    "        #         y_pred = torch.max(logits[i], 1).indices\n",
    "        #         score = f1_score(labels[i], y_pred, average='macro')\n",
    "        #         sumList.append(score)\n",
    "        #     avg = sum(sumList) / len(labels)\n",
    "        #     return avg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # \"\"\"\n",
    "        # 1. Iterate over the batch:\n",
    "        #     for each_label in labels.cpu():\n",
    "        #         shorten the length of the list to its true length using attention list and the function [true_length]\n",
    "        #\n",
    "        #     for each_logit in outputs.logits.cpu():\n",
    "        #         use torch.max(outputs.logits.cpu()[0], 1) to get the indices for each logit (best label prediction)\n",
    "        #         shorten the indices to its proper label length\n",
    "        #         compare the indices to the labels\n",
    "        # \"\"\"\n",
    "        def true_length(y_attention_mask):  # finds the start and stop of the actual sequence\n",
    "            switch = False\n",
    "            start = 0\n",
    "            stop = 0\n",
    "            counter = 0\n",
    "            attention_mask = list(y_attention_mask)\n",
    "            for i in attention_mask:\n",
    "                if int(i) == 1 and switch == False:\n",
    "                    switch = True\n",
    "                    start = counter\n",
    "                elif int(i) == 0 and switch == True:\n",
    "                    stop = counter\n",
    "                    break\n",
    "                elif counter == 511:\n",
    "                    stop = 512\n",
    "                counter += 1\n",
    "            return (start, stop)\n",
    "\n",
    "\n",
    "        def short_clean(attention_mask, labels, logits): #attention_mask, labels.cpu(), outputs.logits.cpu()\n",
    "\n",
    "            def true_length(y_attention_mask):  # finds the start and stop of the actual sequence\n",
    "                switch = False\n",
    "                start = 0\n",
    "                stop = 0\n",
    "                counter = 0\n",
    "                attention_mask = list(y_attention_mask)\n",
    "                for i in attention_mask:\n",
    "                    if int(i) == 1 and switch == False:\n",
    "                        switch = True\n",
    "                        start = counter\n",
    "                    elif int(i) == 0 and switch == True:\n",
    "                        stop = counter\n",
    "                        break\n",
    "                    counter += 1\n",
    "                return (start, stop)\n",
    "\n",
    "            masterPred = []\n",
    "            masterTrue = []\n",
    "            for batch_index in range(len(labels)):\n",
    "                real_len = true_length(attention_mask[batch_index])\n",
    "                predIndecies = torch.max(outputs.logits.cpu()[batch_index], 1).indices\n",
    "                start = real_len[0]\n",
    "                stop = real_len[1]\n",
    "                currentTrue = torch.LongTensor(labels[batch_index][start:stop])\n",
    "                currentPred = torch.LongTensor(predIndecies[start:stop])\n",
    "                if len(currentTrue) == 0:\n",
    "                    masterTrue.append(currentTrue.tolist())\n",
    "                    masterPred.append(currentPred.tolist())\n",
    "                    print(f\"CURRENT-PRED LEN: {len(currentPred)}\")\n",
    "                    print(f\"CURRENT-TRUE LEN:{len(currentTrue)}\")\n",
    "\n",
    "            return (masterTrue, masterPred)\n",
    "\n",
    "        master = short_clean(attention_mask, labels.cpu(), outputs.logits.cpu())\n",
    "        print(\"###################################\")\n",
    "        print(f\"MASTER-TRUE: {master[0]}\")\n",
    "        print(\"###################################\")\n",
    "        print(f\"MASTER-PRED: {master[1]}\")\n",
    "        print(\"###################################\")\n",
    "        print(\"=======\")\n",
    "        print(f\"LABEL LEN: {len(labels.cpu())}\")\n",
    "        for i in range(len(labels.cpu())):\n",
    "            print(f\"SINGLE LABEL LEN: {len(labels.cpu()[i])}\")\n",
    "            print(f\"ATTENTION LEN: {len(attention_mask[i])}\")\n",
    "            #print(attention_mask[i])\n",
    "            print(f\"TRUE LEN: {true_length(attention_mask[i])}\")\n",
    "        print(\"=======\")\n",
    "        print(f\"LABELS: {labels.cpu()}\")\n",
    "        print(\"||||||||||||||||||||||||||||\")\n",
    "        print(\"=======\")\n",
    "        print(f\"LOGITS LEN: {len(outputs.logits.cpu())}\")\n",
    "        for i in outputs.logits.cpu():\n",
    "            print(f\"SINGLE LOGIT LEN: {len(i)}\")\n",
    "        print(f\"LOGIT SINGLE LIST LEN: {len(outputs.logits.cpu()[0][0])}\")\n",
    "        b_logit = torch.max(outputs.logits.cpu()[0], 1)\n",
    "        b_logit_indices = torch.max(outputs.logits.cpu()[0], 1).indices\n",
    "        print(f\"LOGIT BEST: {b_logit}\")\n",
    "        print(f\"LOGIT BEST INDICES: {b_logit_indices}\")\n",
    "        print(\"=======\")\n",
    "        print(f\"LOGITS: {outputs.logits.cpu()}\")\n",
    "\n",
    "        # accuracy = label_average_precision(labels.cpu(), logits=outputs.logits.cpu()) #replaced get_balanced_accuracy(labels.cpu(), logits=outputs.logits.cpu()) with label ranking average precision\n",
    "\n",
    "        # def balanced_accuracy_score(labels, logits):\n",
    "        #     sumList = []\n",
    "        #     for i in range(len(labels)):\n",
    "        #         y_predList = []\n",
    "        #         trueList = []\n",
    "        #         y_pred = logits[i]\n",
    "        #         previous = 0\n",
    "        #         for lab in labels[i]:\n",
    "        #             if lab == -100:\n",
    "        #                 y_predList.append(y_pred[previous])\n",
    "        #                 trueList.append(previous)\n",
    "        #             else:\n",
    "        #                 previous = lab\n",
    "        #                 y_predList.append(y_pred[previous])\n",
    "        #                 trueList.append(previous)\n",
    "        #\n",
    "        #         num = average_precision_score(trueList, y_predList)\n",
    "        #         sumList.append(num)\n",
    "        #     big = sum(sumList) / len(labels)\n",
    "        #     return big\n",
    "\n",
    "        def get_bal_acc(labels, logits):\n",
    "            sumList = []\n",
    "            for i in range(len(labels)):\n",
    "                y_pred = torch.max(logits[i], 1).indices\n",
    "                score = balanced_accuracy_score(labels[i], y_pred)\n",
    "                sumList.append(score)\n",
    "            avg = sum(sumList) / len(labels)\n",
    "            return avg\n",
    "\n",
    "        accuracy = get_bal_acc(labels.cpu(), outputs.logits.cpu())\n",
    "\n",
    "        self.log(\n",
    "            \"val_accuracy\",\n",
    "            accuracy,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.use_adafactor:\n",
    "            return Adafactor(\n",
    "                self.parameters(),\n",
    "                lr=self.learning_rate,\n",
    "                eps=(1e-30, 1e-3),\n",
    "                clip_threshold=1.0,\n",
    "                decay_rate=-0.8,\n",
    "                beta1=None,\n",
    "                weight_decay=0.0,\n",
    "                relative_step=False,\n",
    "                scale_parameter=False,\n",
    "                warmup_init=False)\n",
    "        else:\n",
    "            return AdamW(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def save_pretrained(self, pretrained_dir):\n",
    "        self.bert.save_pretrained(self, prtrained_dir)\n",
    "\n",
    "    def predict_classes(self, input_ids, attention_mask, return_logits=False):\n",
    "        output = self.bert(input_ids=input_ids.to(self.device), attention_mask=attention_mask)\n",
    "        if return_logits:\n",
    "            return output.logits\n",
    "        else:\n",
    "            probabilities = F.sigmoid(output.logits)\n",
    "            predictions = torch.argmax(probabilities)\n",
    "            return {\"probabilities\": probabilities, \"predictions\": predictions}\n",
    "\n",
    "    def get_attention(self, input_ids, attention_mask, specific_attention_head: int = None):\n",
    "        output = self.bert(inputs_ids=input_ids.to(self.device), attention_mask=attention_mask)\n",
    "        if specific_attention_head is not None:\n",
    "            last_layer = output.attentions[-1]  # grabs the last layer\n",
    "            all_last_attention_heads = [torch.max(this_input[specific_attention_head], axis=0)[0].indices for this_input in last_layer]\n",
    "            return all_last_attention_heads\n",
    "        return output.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "gpu_idx = 1\n",
    "num_labels = 61\n",
    "model_path = \"/mnt/storage/grid/home/eric/hmm2bert/models/pullin/pullin>1000_best_loss-v1{1GPU}.pt\"\n",
    "data_folder = \"pullin_parsed_data\"\n",
    "strat_val_name = \"embedding_pullin_noDupes_val>1000_stratified_domainPiece.pt\"\n",
    "strat_val_path = f\"/mnt/storage/grid/home/eric/hmm2bert/{data_folder}/{strat_val_name}\"\n",
    "encoded_label_filename = \"encoded_parsed_pullin_noDupes>1000_withAA_not_domain.csv\"\n",
    "encoded_csv = f\"/mnt/storage/grid/home/eric/hmm2bert/{data_folder}/{encoded_label_filename}\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "\n",
    "encoded_test = torch.load(strat_val_path)\n",
    "\n",
    "model = torch.load(model_path)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "meatpipe = pipeline(task='ner', model=model.bert, tokenizer=tokenizer, device=gpu_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d5bd3108ba9f5f5e\n",
      "Reusing dataset csv (/home/eric/.cache/huggingface/datasets/csv/default-d5bd3108ba9f5f5e/0.0.0/2a88c45fed596f9421a2e7f74ab1a3cd012ef75210a5dc1950e8d60ca8d9c66c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'sequence', 'labels', 'start', 'stop']\n"
     ]
    }
   ],
   "source": [
    "# load csv to huggingface dataset AND pandas dataframe\n",
    "dataset = load_dataset('csv', data_files=encoded_csv)\n",
    "df = pd.read_csv(encoded_csv)\n",
    "dataset = dataset['train']\n",
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sequence', 'labels', 'start', 'stop'], dtype='object')\n",
      "Index(['sequence', 'labels'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "df = df.drop([\"start\"], axis=1)\n",
    "df = df.drop([\"stop\"], axis=1)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into train and test, this produces a list with the row positions\n",
    "num_rows_list = list(range(len(df)))\n",
    "strat_train, strat_test = train_test_split(df, test_size=.2, stratify=df['labels'], random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#+++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "['M', 'S', 'R', 'S', 'F', 'E', 'I', 'S', 'L', 'S', 'P', 'A', 'S', 'T', 'P', 'E', 'L', 'N', 'I', 'S', 'N', 'L', 'T', 'S', 'N', 'L', 'I', 'T', 'Y', 'A', 'R', 'D', 'E', 'L', 'T', 'K', 'N', 'L', 'V', 'I', 'F', 'I', 'G', 'K', 'I', 'Y', 'Y', 'Q', 'D', 'E', 'L', 'K', 'T', 'I', 'Y', 'P', 'E', 'A', 'F', 'R', 'E', 'K', 'T', 'N', 'P', 'E', 'A', 'S', 'I', 'A', 'L', 'A', 'I', 'Y', 'Q', 'Q', 'K', 'G', 'I', 'K', 'G', 'L', 'Q', 'D', 'L', 'E', 'G', 'E', 'F', 'A', 'L', 'V', 'I', 'F', 'D', 'R', 'Q', 'K', 'S', 'S', 'L', 'I', 'A', 'L', 'R', 'D', 'P', 'I', 'G', 'S', 'Y', 'P', 'L', 'Y', 'W', 'T', 'F', 'D', 'K', 'H', 'T', 'I', 'R', 'I', 'S', 'S', 'D', 'L', 'Q', 'H', 'L', 'A', 'R', 'Q', 'K', 'K', 'A', 'K', 'I', 'N', 'R', 'D', 'F', 'L', 'A', 'S', 'F', 'L', 'M', 'F', 'P', 'F', 'A', 'F', 'V', 'E', 'L', 'P', 'R', 'E', 'E', 'T', 'A', 'F', 'E', 'G', 'I', 'Q', 'R', 'L', 'S', 'P', 'G', 'S', 'C', 'G', 'E', 'F', 'Y', 'P', 'P', 'N', 'L', 'V', 'Q', 'K', 'H', 'W', 'T', 'W', 'N', 'W', 'E', 'E', 'K', 'I', 'A', 'P', 'I', 'S', 'D', 'L', 'T', 'L', 'A', 'A', 'A', 'A', 'Q', 'Q', 'F', 'R', 'Q', 'I', 'F', 'Q', 'H', 'S', 'I', 'R', 'E', 'R', 'C', 'R', 'E', 'G', 'K', 'V', 'A', 'S', 'H', 'L', 'S', 'G', 'G', 'M', 'D', 'S', 'S', 'S', 'I', 'V', 'C', 'L', 'A', 'R', 'D', 'S', 'I', 'G', 'E', 'R', 'K', 'L', 'L', 'T', 'L', 'S', 'L', 'V', 'Y', 'Q', 'M', 'P', 'S', 'L', 'V', 'K', 'E', 'T', 'D', 'Y', 'I', 'N', 'L', 'I', 'L', 'Q', 'Q', 'K', 'A', 'A', 'I', 'E', 'P', 'Y', 'F', 'L', 'D', 'G', 'D', 'Q', 'L', 'L', 'D', 'F', 'D', 'W', 'F', 'S', 'D', 'R', 'I', 'P', 'P', 'H', 'D', 'E', 'P', 'Y', 'P', 'G', 'L', 'F', 'H', 'L', 'A', 'M', 'E', 'K', 'I', 'L', 'V', 'D', 'R', 'A', 'A', 'E', 'L', 'G', 'V', 'N', 'T', 'I', 'L', 'S', 'G', 'G', 'G', 'A', 'E', 'L', 'V', 'L', 'E', 'S', 'N', 'R', 'Y', 'H', 'L', 'A', 'D', 'L', 'L', 'H', 'Q', 'G', 'Q', 'W', 'Q', 'E', 'T', 'L', 'Q', 'L', 'A', 'R', 'W', 'W', 'A', 'K', 'T', 'K', 'N', 'E', 'S', 'L', 'W', 'S', 'I', 'L', 'A', 'E', 'L', 'A', 'I', 'F', 'P', 'L', 'S', 'P', 'A', 'F', 'L', 'K', 'P', 'G', 'I', 'A', 'T', 'F', 'W', 'R', 'R', 'G', 'Y', 'G', 'T', 'W', 'P', 'K', 'L', 'S', 'E', 'F', 'A', 'I', 'P', 'P', 'W', 'I', 'K', 'A', 'D', 'F', 'A', 'Q', 'E', 'Y', 'Q', 'V', 'Y', 'P', 'K', 'T', 'L', 'A', 'T', 'L', 'G', 'Q', 'I', 'Y', 'R', 'Y', 'P', 'V', 'E', 'L', 'S', 'F', 'N', 'R', 'L', 'G', 'L', 'Q', 'T', 'A', 'I', 'G', 'N', 'W', 'A', 'N', 'W', 'Y', 'L', 'A', 'N', 'P', 'A', 'G', 'M', 'R', 'I', 'S', 'Q', 'P', 'F', 'L', 'D', 'P', 'R', 'V', 'I', 'C', 'Y', 'C', 'L', 'G', 'L', 'P', 'R', 'Q', 'F', 'R', 'E', 'V', 'P', 'G', 'M', 'V', 'K', 'P', 'L', 'L', 'Q', 'S', 'A', 'L', 'Q', 'G', 'I', 'L', 'P', 'E', 'A', 'I', 'R', 'T', 'R', 'R', 'F', 'K', 'A', 'N', 'F', 'N', 'A', 'V', 'Y', 'W', 'Q', 'G', 'L', 'S', 'R', 'R', 'L', 'T', 'Q', 'L', 'E', 'T', 'M', 'V', 'E', 'E', 'S', 'A', 'I', 'E', 'D', 'L', 'G', 'I', 'F', 'D', 'K', 'T', 'R', 'L', 'I', 'E', 'V', 'L', 'R', 'Q', 'H', 'S', 'L', 'G', 'I', 'G', 'D', 'V', 'K', 'S', 'G', 'S', 'R', 'I', 'S', 'S', 'S', 'L', 'A', 'V', 'I', 'A', 'W', 'F', 'D', 'R', 'L', 'S', 'Q', 'T']\n",
      "600\n",
      "512\n",
      "['M', 'S', 'R', 'S', 'F', 'E', 'I', 'S', 'L', 'S', 'P', 'A', 'S', 'T', 'P', 'E', 'L', 'N', 'I', 'S', 'N', 'L', 'T', 'S', 'N', 'L', 'I', 'T', 'Y', 'A', 'R', 'D', 'E', 'L', 'T', 'K', 'N', 'L', 'V', 'I', 'F', 'I', 'G', 'K', 'I', 'Y', 'Y', 'Q', 'D', 'E', 'L', 'K', 'T', 'I', 'Y', 'P', 'E', 'A', 'F', 'R', 'E', 'K', 'T', 'N', 'P', 'E', 'A', 'S', 'I', 'A', 'L', 'A', 'I', 'Y', 'Q', 'Q', 'K', 'G', 'I', 'K', 'G', 'L', 'Q', 'D', 'L', 'E', 'G', 'E', 'F', 'A', 'L', 'V', 'I', 'F', 'D', 'R', 'Q', 'K', 'S', 'S', 'L', 'I', 'A', 'L', 'R', 'D', 'P', 'I', 'G', 'S', 'Y', 'P', 'L', 'Y', 'W', 'T', 'F', 'D', 'K', 'H', 'T', 'I', 'R', 'I', 'S', 'S', 'D', 'L', 'Q', 'H', 'L', 'A', 'R', 'Q', 'K', 'K', 'A', 'K', 'I', 'N', 'R', 'D', 'F', 'L', 'A', 'S', 'F', 'L', 'M', 'F', 'P', 'F', 'A', 'F', 'V', 'E', 'L', 'P', 'R', 'E', 'E', 'T', 'A', 'F', 'E', 'G', 'I', 'Q', 'R', 'L', 'S', 'P', 'G', 'S', 'C', 'G', 'E', 'F', 'Y', 'P', 'P', 'N', 'L', 'V', 'Q', 'K', 'H', 'W', 'T', 'W', 'N', 'W', 'E', 'E', 'K', 'I', 'A', 'P', 'I', 'S', 'D', 'L', 'T', 'L', 'A', 'A', 'A', 'A', 'Q', 'Q', 'F', 'R', 'Q', 'I', 'F', 'Q', 'H', 'S', 'I', 'R', 'E', 'R', 'C', 'R', 'E', 'G', 'K', 'V', 'A', 'S', 'H', 'L', 'S', 'G', 'G', 'M', 'D', 'S', 'S', 'S', 'I', 'V', 'C', 'L', 'A', 'R', 'D', 'S', 'I', 'G', 'E', 'R', 'K', 'L', 'L', 'T', 'L', 'S', 'L', 'V', 'Y', 'Q', 'M', 'P', 'S', 'L', 'V', 'K', 'E', 'T', 'D', 'Y', 'I', 'N', 'L', 'I', 'L', 'Q', 'Q', 'K', 'A', 'A', 'I', 'E', 'P', 'Y', 'F', 'L', 'D', 'G', 'D', 'Q', 'L', 'L', 'D', 'F', 'D', 'W', 'F', 'S', 'D', 'R', 'I', 'P', 'P', 'H', 'D', 'E', 'P', 'Y', 'P', 'G', 'L', 'F', 'H', 'L', 'A', 'M', 'E', 'K', 'I', 'L', 'V', 'D', 'R', 'A', 'A', 'E', 'L', 'G', 'V', 'N', 'T', 'I', 'L', 'S', 'G', 'G', 'G', 'A', 'E', 'L', 'V', 'L', 'E', 'S', 'N', 'R', 'Y', 'H', 'L', 'A', 'D', 'L', 'L', 'H', 'Q', 'G', 'Q', 'W', 'Q', 'E', 'T', 'L', 'Q', 'L', 'A', 'R', 'W', 'W', 'A', 'K', 'T', 'K', 'N', 'E', 'S', 'L', 'W', 'S', 'I', 'L', 'A', 'E', 'L', 'A', 'I', 'F', 'P', 'L', 'S', 'P', 'A', 'F', 'L', 'K', 'P', 'G', 'I', 'A', 'T', 'F', 'W', 'R', 'R', 'G', 'Y', 'G', 'T', 'W', 'P', 'K', 'L', 'S', 'E', 'F', 'A', 'I', 'P', 'P', 'W', 'I', 'K', 'A', 'D', 'F', 'A', 'Q', 'E', 'Y', 'Q', 'V', 'Y', 'P', 'K', 'T', 'L', 'A', 'T', 'L', 'G', 'Q', 'I', 'Y', 'R', 'Y', 'P', 'V', 'E', 'L', 'S', 'F', 'N', 'R', 'L', 'G', 'L', 'Q', 'T', 'A', 'I', 'G', 'N', 'W', 'A', 'N', 'W', 'Y', 'L', 'A', 'N', 'P', 'A', 'G', 'M', 'R', 'I', 'S', 'Q', 'P', 'F', 'L', 'D', 'P', 'R', 'V', 'I', 'C', 'Y', 'C', 'L', 'G', 'L', 'P', 'R', 'Q', 'F', 'R', 'E', 'V', 'P', 'G', 'M', 'V', 'K', 'P', 'L', 'L', 'Q', 'S', 'A', 'L']\n"
     ]
    }
   ],
   "source": [
    "loc_num = 6000\n",
    "test_sequence = list(strat_test.iloc[loc_num][\"sequence\"])\n",
    "print(strat_test.iloc[loc_num][\"labels\"])\n",
    "print(test_sequence)\n",
    "\n",
    "print(len(test_sequence))\n",
    "if len(test_sequence) < 512:\n",
    "    while len(test_sequence) < 512:\n",
    "        test_sequence.append(-100)\n",
    "elif len(test_sequence) > 512:\n",
    "    test_sequence = test_sequence[:512]\n",
    "\n",
    "print(len(test_sequence))\n",
    "test_sequence = str(test_sequence)\n",
    "print(test_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCSWTRWRRGVGPRVWWPRRWRSGSGTWVRGWGSICRXXXXRPGLDRGEATVVPLRVDTAALRTRTDEIPALLRALAPARRATAASGSAPAPGPDDSPSRRLAELPAPERHRAVLHLVRSQVAAVLGHGSAEAIGADRAFQELGFDSLAATELRNQLNTLTGLRLPATLVFDHPNALAVTEVVEEELAAAHPASGAGGATGDDDGVRRALSAIPARRLRDAGLAETLLELAADSDEMSDTDRDALLAAFDGDDEDDASGPYDESDGAAGTAGTGTATEPGADALRAARAETARLRRDNRRLTSAQHEPIAMHGXXXXPATTRSSPSPRTVAGTCRSSATPTATTRTACTPGKAVSSTGRPTSTPPSSASRRARRSAWTRSSAWHWRCPGRPWSGPGSTRPRSRAAGPASSPA\n",
      "M C S W T R W R R G V G P R V W W P R R W R S G S G T W V R G W G S I C R X X X X R P G L D R G E A T V V P L R V D T A A L R T R T D E I P A L L R A L A P A R R A T A A S G S A P A P G P D D S P S R R L A E L P A P E R H R A V L H L V R S Q V A A V L G H G S A E A I G A D R A F Q E L G F D S L A A T E L R N Q L N T L T G L R L P A T L V F D H P N A L A V T E V V E E E L A A A H P A S G A G G A T G D D D G V R R A L S A I P A R R L R D A G L A E T L L E L A A D S D E M S D T D R D A L L A A F D G D D E D D A S G P Y D E S D G A A G T A G T G T A T E P G A D A L R A A R A E T A R L R R D N R R L T S A Q H E P I A M H G X X X X P A T T R S S P S P R T V A G T C R S S A T P T A T T R T A C T P G K A V S S T G R P T S T P P S S A S R R A R R S A W T R S S A W H W R C P G R P W S G P G S T R P R S R A A G P A S S P A\n"
     ]
    }
   ],
   "source": [
    "loc_num = 1\n",
    "test_sequence = strat_test.iloc[loc_num][\"sequence\"]\n",
    "print(test_sequence)\n",
    "test_sequence = \" \".join(test_sequence)\n",
    "print(test_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'M', 'score': 0.8470281958580017, 'entity': 'LABEL_5', 'index': 1, 'start': None, 'end': None}\n",
      "{'word': 'C', 'score': 0.36774003505706787, 'entity': 'LABEL_5', 'index': 2, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.3681032955646515, 'entity': 'LABEL_0', 'index': 3, 'start': None, 'end': None}\n",
      "{'word': 'W', 'score': 0.3364647328853607, 'entity': 'LABEL_0', 'index': 4, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.6021129488945007, 'entity': 'LABEL_5', 'index': 5, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.2747739255428314, 'entity': 'LABEL_5', 'index': 6, 'start': None, 'end': None}\n",
      "{'word': 'W', 'score': 0.6950332522392273, 'entity': 'LABEL_0', 'index': 7, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.3791675269603729, 'entity': 'LABEL_0', 'index': 8, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.395891398191452, 'entity': 'LABEL_0', 'index': 9, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.6924379467964172, 'entity': 'LABEL_5', 'index': 10, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.7797529101371765, 'entity': 'LABEL_0', 'index': 11, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.6055543422698975, 'entity': 'LABEL_0', 'index': 12, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.6738021373748779, 'entity': 'LABEL_0', 'index': 13, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.25599220395088196, 'entity': 'LABEL_23', 'index': 14, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.20603060722351074, 'entity': 'LABEL_0', 'index': 15, 'start': None, 'end': None}\n",
      "{'word': 'W', 'score': 0.1754656732082367, 'entity': 'LABEL_59', 'index': 16, 'start': None, 'end': None}\n",
      "{'word': 'W', 'score': 0.26989099383354187, 'entity': 'LABEL_0', 'index': 17, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.5894174575805664, 'entity': 'LABEL_0', 'index': 18, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.3570159077644348, 'entity': 'LABEL_23', 'index': 19, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.48544034361839294, 'entity': 'LABEL_0', 'index': 20, 'start': None, 'end': None}\n",
      "{'word': 'W', 'score': 0.8321093916893005, 'entity': 'LABEL_0', 'index': 21, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.4400961697101593, 'entity': 'LABEL_0', 'index': 22, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.47794705629348755, 'entity': 'LABEL_23', 'index': 23, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.5610373616218567, 'entity': 'LABEL_23', 'index': 24, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.47177600860595703, 'entity': 'LABEL_23', 'index': 25, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.703528106212616, 'entity': 'LABEL_23', 'index': 26, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.7255221605300903, 'entity': 'LABEL_5', 'index': 27, 'start': None, 'end': None}\n",
      "{'word': 'W', 'score': 0.3315551280975342, 'entity': 'LABEL_23', 'index': 28, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.5488693118095398, 'entity': 'LABEL_0', 'index': 29, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.5039585828781128, 'entity': 'LABEL_0', 'index': 30, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.5769016146659851, 'entity': 'LABEL_23', 'index': 31, 'start': None, 'end': None}\n",
      "{'word': 'W', 'score': 0.49375903606414795, 'entity': 'LABEL_23', 'index': 32, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.6072007417678833, 'entity': 'LABEL_23', 'index': 33, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.38957029581069946, 'entity': 'LABEL_0', 'index': 34, 'start': None, 'end': None}\n",
      "{'word': 'I', 'score': 0.19558414816856384, 'entity': 'LABEL_23', 'index': 35, 'start': None, 'end': None}\n",
      "{'word': 'C', 'score': 0.20998266339302063, 'entity': 'LABEL_0', 'index': 36, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.37186259031295776, 'entity': 'LABEL_59', 'index': 37, 'start': None, 'end': None}\n",
      "{'word': 'X', 'score': 0.21988943219184875, 'entity': 'LABEL_23', 'index': 38, 'start': None, 'end': None}\n",
      "{'word': 'X', 'score': 0.19053295254707336, 'entity': 'LABEL_59', 'index': 39, 'start': None, 'end': None}\n",
      "{'word': 'X', 'score': 0.24193520843982697, 'entity': 'LABEL_23', 'index': 40, 'start': None, 'end': None}\n",
      "{'word': 'X', 'score': 0.28461065888404846, 'entity': 'LABEL_59', 'index': 41, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.8714767098426819, 'entity': 'LABEL_59', 'index': 42, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.21052195131778717, 'entity': 'LABEL_59', 'index': 43, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.25344789028167725, 'entity': 'LABEL_23', 'index': 44, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9993531703948975, 'entity': 'LABEL_0', 'index': 45, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.3664916753768921, 'entity': 'LABEL_23', 'index': 46, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.45438873767852783, 'entity': 'LABEL_0', 'index': 47, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.3523479998111725, 'entity': 'LABEL_59', 'index': 48, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.8982958197593689, 'entity': 'LABEL_59', 'index': 49, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.41754981875419617, 'entity': 'LABEL_0', 'index': 50, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9436507821083069, 'entity': 'LABEL_54', 'index': 51, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.8433008193969727, 'entity': 'LABEL_0', 'index': 52, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.9686036705970764, 'entity': 'LABEL_0', 'index': 53, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.8350833058357239, 'entity': 'LABEL_0', 'index': 54, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9935997724533081, 'entity': 'LABEL_0', 'index': 55, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9149448275566101, 'entity': 'LABEL_0', 'index': 56, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.9996736645698547, 'entity': 'LABEL_0', 'index': 57, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9947072267532349, 'entity': 'LABEL_0', 'index': 58, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9976887702941895, 'entity': 'LABEL_0', 'index': 59, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9985893964767456, 'entity': 'LABEL_0', 'index': 60, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9992644190788269, 'entity': 'LABEL_0', 'index': 61, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9996262788772583, 'entity': 'LABEL_0', 'index': 62, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9994407892227173, 'entity': 'LABEL_0', 'index': 63, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9994423389434814, 'entity': 'LABEL_0', 'index': 64, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9974755048751831, 'entity': 'LABEL_0', 'index': 65, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9985942840576172, 'entity': 'LABEL_0', 'index': 66, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9260602593421936, 'entity': 'LABEL_0', 'index': 67, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9376710653305054, 'entity': 'LABEL_0', 'index': 68, 'start': None, 'end': None}\n",
      "{'word': 'I', 'score': 0.9960179328918457, 'entity': 'LABEL_0', 'index': 69, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9468830227851868, 'entity': 'LABEL_0', 'index': 70, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9753748178482056, 'entity': 'LABEL_0', 'index': 71, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9984763860702515, 'entity': 'LABEL_0', 'index': 72, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9992489814758301, 'entity': 'LABEL_0', 'index': 73, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9878391027450562, 'entity': 'LABEL_0', 'index': 74, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9977505803108215, 'entity': 'LABEL_0', 'index': 75, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9995819330215454, 'entity': 'LABEL_0', 'index': 76, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9944164156913757, 'entity': 'LABEL_0', 'index': 77, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9482909440994263, 'entity': 'LABEL_0', 'index': 78, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9894818663597107, 'entity': 'LABEL_0', 'index': 79, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9795098900794983, 'entity': 'LABEL_0', 'index': 80, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.939319908618927, 'entity': 'LABEL_0', 'index': 81, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9457992315292358, 'entity': 'LABEL_0', 'index': 82, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.5647093057632446, 'entity': 'LABEL_0', 'index': 83, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.8582325577735901, 'entity': 'LABEL_0', 'index': 84, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.823189377784729, 'entity': 'LABEL_0', 'index': 85, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.6191418766975403, 'entity': 'LABEL_0', 'index': 86, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.5060452818870544, 'entity': 'LABEL_0', 'index': 87, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.5603644847869873, 'entity': 'LABEL_0', 'index': 88, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.8812428712844849, 'entity': 'LABEL_0', 'index': 89, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.8544742465019226, 'entity': 'LABEL_0', 'index': 90, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.8822761178016663, 'entity': 'LABEL_0', 'index': 91, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9035841822624207, 'entity': 'LABEL_0', 'index': 92, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.8631256818771362, 'entity': 'LABEL_0', 'index': 93, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.8212668299674988, 'entity': 'LABEL_0', 'index': 94, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.630678117275238, 'entity': 'LABEL_0', 'index': 95, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.6141810417175293, 'entity': 'LABEL_0', 'index': 96, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.5639376044273376, 'entity': 'LABEL_0', 'index': 97, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.690212070941925, 'entity': 'LABEL_59', 'index': 98, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.6891059875488281, 'entity': 'LABEL_59', 'index': 99, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.6761747002601624, 'entity': 'LABEL_59', 'index': 100, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.6667577028274536, 'entity': 'LABEL_59', 'index': 101, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.6344175934791565, 'entity': 'LABEL_59', 'index': 102, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.6399044990539551, 'entity': 'LABEL_59', 'index': 103, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.6683628559112549, 'entity': 'LABEL_59', 'index': 104, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.6627960205078125, 'entity': 'LABEL_59', 'index': 105, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.7624825239181519, 'entity': 'LABEL_59', 'index': 106, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9951030611991882, 'entity': 'LABEL_59', 'index': 107, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9980478286743164, 'entity': 'LABEL_59', 'index': 108, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9996274709701538, 'entity': 'LABEL_59', 'index': 109, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.999789834022522, 'entity': 'LABEL_59', 'index': 110, 'start': None, 'end': None}\n",
      "{'word': 'H', 'score': 0.9997923374176025, 'entity': 'LABEL_59', 'index': 111, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9997894167900085, 'entity': 'LABEL_59', 'index': 112, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9997581243515015, 'entity': 'LABEL_59', 'index': 113, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.9997654557228088, 'entity': 'LABEL_59', 'index': 114, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9997981786727905, 'entity': 'LABEL_59', 'index': 115, 'start': None, 'end': None}\n",
      "{'word': 'H', 'score': 0.9997662901878357, 'entity': 'LABEL_59', 'index': 116, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9992831349372864, 'entity': 'LABEL_59', 'index': 117, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.9991833567619324, 'entity': 'LABEL_59', 'index': 118, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9995593428611755, 'entity': 'LABEL_59', 'index': 119, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.998741626739502, 'entity': 'LABEL_59', 'index': 120, 'start': None, 'end': None}\n",
      "{'word': 'Q', 'score': 0.9926347136497498, 'entity': 'LABEL_59', 'index': 121, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.9237112402915955, 'entity': 'LABEL_59', 'index': 122, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9730416536331177, 'entity': 'LABEL_59', 'index': 123, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9404906630516052, 'entity': 'LABEL_59', 'index': 124, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.9558712840080261, 'entity': 'LABEL_59', 'index': 125, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.7543773055076599, 'entity': 'LABEL_59', 'index': 126, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.6702061891555786, 'entity': 'LABEL_59', 'index': 127, 'start': None, 'end': None}\n",
      "{'word': 'H', 'score': 0.6098209023475647, 'entity': 'LABEL_0', 'index': 128, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.5959515571594238, 'entity': 'LABEL_59', 'index': 129, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.5984935760498047, 'entity': 'LABEL_0', 'index': 130, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.6064128279685974, 'entity': 'LABEL_0', 'index': 131, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.8779671788215637, 'entity': 'LABEL_59', 'index': 132, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.5948885083198547, 'entity': 'LABEL_59', 'index': 133, 'start': None, 'end': None}\n",
      "{'word': 'I', 'score': 0.6843934059143066, 'entity': 'LABEL_0', 'index': 134, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.7346265912055969, 'entity': 'LABEL_59', 'index': 135, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.7515439987182617, 'entity': 'LABEL_59', 'index': 136, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.814024806022644, 'entity': 'LABEL_59', 'index': 137, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.7953214645385742, 'entity': 'LABEL_59', 'index': 138, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9721243381500244, 'entity': 'LABEL_59', 'index': 139, 'start': None, 'end': None}\n",
      "{'word': 'F', 'score': 0.5551648736000061, 'entity': 'LABEL_0', 'index': 140, 'start': None, 'end': None}\n",
      "{'word': 'Q', 'score': 0.9852750301361084, 'entity': 'LABEL_59', 'index': 141, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9676927328109741, 'entity': 'LABEL_59', 'index': 142, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.6845183372497559, 'entity': 'LABEL_59', 'index': 143, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.8840599060058594, 'entity': 'LABEL_59', 'index': 144, 'start': None, 'end': None}\n",
      "{'word': 'F', 'score': 0.7216233611106873, 'entity': 'LABEL_59', 'index': 145, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.7634340524673462, 'entity': 'LABEL_59', 'index': 146, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.7053728103637695, 'entity': 'LABEL_59', 'index': 147, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.5362730622291565, 'entity': 'LABEL_59', 'index': 148, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.4767453074455261, 'entity': 'LABEL_59', 'index': 149, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.682132363319397, 'entity': 'LABEL_59', 'index': 150, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.6069178581237793, 'entity': 'LABEL_5', 'index': 151, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.42534810304641724, 'entity': 'LABEL_0', 'index': 152, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9985557794570923, 'entity': 'LABEL_0', 'index': 153, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9976387023925781, 'entity': 'LABEL_0', 'index': 154, 'start': None, 'end': None}\n",
      "{'word': 'N', 'score': 0.984621524810791, 'entity': 'LABEL_0', 'index': 155, 'start': None, 'end': None}\n",
      "{'word': 'Q', 'score': 0.5999599695205688, 'entity': 'LABEL_0', 'index': 156, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9992448091506958, 'entity': 'LABEL_0', 'index': 157, 'start': None, 'end': None}\n",
      "{'word': 'N', 'score': 0.985038161277771, 'entity': 'LABEL_0', 'index': 158, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9980303049087524, 'entity': 'LABEL_0', 'index': 159, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.998822808265686, 'entity': 'LABEL_0', 'index': 160, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9977498650550842, 'entity': 'LABEL_0', 'index': 161, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9953188896179199, 'entity': 'LABEL_0', 'index': 162, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9991030097007751, 'entity': 'LABEL_0', 'index': 163, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.998255729675293, 'entity': 'LABEL_0', 'index': 164, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9995740652084351, 'entity': 'LABEL_0', 'index': 165, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9992457032203674, 'entity': 'LABEL_0', 'index': 166, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9994999766349792, 'entity': 'LABEL_0', 'index': 167, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9993826746940613, 'entity': 'LABEL_0', 'index': 168, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9996328353881836, 'entity': 'LABEL_0', 'index': 169, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.9996688961982727, 'entity': 'LABEL_0', 'index': 170, 'start': None, 'end': None}\n",
      "{'word': 'F', 'score': 0.999653160572052, 'entity': 'LABEL_0', 'index': 171, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9997122883796692, 'entity': 'LABEL_0', 'index': 172, 'start': None, 'end': None}\n",
      "{'word': 'H', 'score': 0.9994995594024658, 'entity': 'LABEL_0', 'index': 173, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9995518326759338, 'entity': 'LABEL_0', 'index': 174, 'start': None, 'end': None}\n",
      "{'word': 'N', 'score': 0.9994401335716248, 'entity': 'LABEL_0', 'index': 175, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9994878172874451, 'entity': 'LABEL_0', 'index': 176, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9996610283851624, 'entity': 'LABEL_0', 'index': 177, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9996216893196106, 'entity': 'LABEL_0', 'index': 178, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.9997104406356812, 'entity': 'LABEL_0', 'index': 179, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9997003674507141, 'entity': 'LABEL_0', 'index': 180, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9997177720069885, 'entity': 'LABEL_0', 'index': 181, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.999724805355072, 'entity': 'LABEL_0', 'index': 182, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.9997252821922302, 'entity': 'LABEL_0', 'index': 183, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9997360706329346, 'entity': 'LABEL_0', 'index': 184, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9997416138648987, 'entity': 'LABEL_0', 'index': 185, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9997439980506897, 'entity': 'LABEL_0', 'index': 186, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9997262358665466, 'entity': 'LABEL_0', 'index': 187, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9997427463531494, 'entity': 'LABEL_0', 'index': 188, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9997382760047913, 'entity': 'LABEL_0', 'index': 189, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9997054934501648, 'entity': 'LABEL_0', 'index': 190, 'start': None, 'end': None}\n",
      "{'word': 'H', 'score': 0.9996113777160645, 'entity': 'LABEL_0', 'index': 191, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9995465874671936, 'entity': 'LABEL_0', 'index': 192, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9996940493583679, 'entity': 'LABEL_0', 'index': 193, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9995936751365662, 'entity': 'LABEL_0', 'index': 194, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9990494847297668, 'entity': 'LABEL_0', 'index': 195, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9990782141685486, 'entity': 'LABEL_0', 'index': 196, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9966227412223816, 'entity': 'LABEL_0', 'index': 197, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9952028393745422, 'entity': 'LABEL_0', 'index': 198, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9982283115386963, 'entity': 'LABEL_0', 'index': 199, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9993788599967957, 'entity': 'LABEL_0', 'index': 200, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9953458309173584, 'entity': 'LABEL_0', 'index': 201, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9972088932991028, 'entity': 'LABEL_0', 'index': 202, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9968583583831787, 'entity': 'LABEL_0', 'index': 203, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9908485412597656, 'entity': 'LABEL_0', 'index': 204, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9993823766708374, 'entity': 'LABEL_0', 'index': 205, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.998970091342926, 'entity': 'LABEL_0', 'index': 206, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.996657133102417, 'entity': 'LABEL_0', 'index': 207, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.995588481426239, 'entity': 'LABEL_0', 'index': 208, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9898508191108704, 'entity': 'LABEL_0', 'index': 209, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9995629191398621, 'entity': 'LABEL_0', 'index': 210, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9994786381721497, 'entity': 'LABEL_0', 'index': 211, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9995189309120178, 'entity': 'LABEL_0', 'index': 212, 'start': None, 'end': None}\n",
      "{'word': 'I', 'score': 0.9989924430847168, 'entity': 'LABEL_0', 'index': 213, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9994199872016907, 'entity': 'LABEL_0', 'index': 214, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9992460608482361, 'entity': 'LABEL_0', 'index': 215, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9990653395652771, 'entity': 'LABEL_0', 'index': 216, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9981204271316528, 'entity': 'LABEL_0', 'index': 217, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9995671510696411, 'entity': 'LABEL_0', 'index': 218, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9977800846099854, 'entity': 'LABEL_0', 'index': 219, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9996868371963501, 'entity': 'LABEL_0', 'index': 220, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9996127486228943, 'entity': 'LABEL_0', 'index': 221, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9938555955886841, 'entity': 'LABEL_0', 'index': 222, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9996736645698547, 'entity': 'LABEL_0', 'index': 223, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9994917511940002, 'entity': 'LABEL_0', 'index': 224, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9996803998947144, 'entity': 'LABEL_0', 'index': 225, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.999566912651062, 'entity': 'LABEL_0', 'index': 226, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.999712347984314, 'entity': 'LABEL_0', 'index': 227, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9997198581695557, 'entity': 'LABEL_0', 'index': 228, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9996910095214844, 'entity': 'LABEL_0', 'index': 229, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9997195601463318, 'entity': 'LABEL_0', 'index': 230, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9997381567955017, 'entity': 'LABEL_0', 'index': 231, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9997380971908569, 'entity': 'LABEL_0', 'index': 232, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9996329545974731, 'entity': 'LABEL_0', 'index': 233, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9996957778930664, 'entity': 'LABEL_0', 'index': 234, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9997364282608032, 'entity': 'LABEL_0', 'index': 235, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9993492364883423, 'entity': 'LABEL_0', 'index': 236, 'start': None, 'end': None}\n",
      "{'word': 'M', 'score': 0.9994915127754211, 'entity': 'LABEL_0', 'index': 237, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.999301552772522, 'entity': 'LABEL_0', 'index': 238, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9993777275085449, 'entity': 'LABEL_0', 'index': 239, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9966654181480408, 'entity': 'LABEL_0', 'index': 240, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9431391358375549, 'entity': 'LABEL_0', 'index': 241, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.7654155492782593, 'entity': 'LABEL_0', 'index': 242, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.8361757397651672, 'entity': 'LABEL_0', 'index': 243, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9940803050994873, 'entity': 'LABEL_0', 'index': 244, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.999478280544281, 'entity': 'LABEL_0', 'index': 245, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.999521017074585, 'entity': 'LABEL_0', 'index': 246, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9995176792144775, 'entity': 'LABEL_0', 'index': 247, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9987086653709412, 'entity': 'LABEL_0', 'index': 248, 'start': None, 'end': None}\n",
      "{'word': 'F', 'score': 0.9995275735855103, 'entity': 'LABEL_0', 'index': 249, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9991689920425415, 'entity': 'LABEL_0', 'index': 250, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9996885061264038, 'entity': 'LABEL_0', 'index': 251, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9996594190597534, 'entity': 'LABEL_0', 'index': 252, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9996517896652222, 'entity': 'LABEL_0', 'index': 253, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9995213150978088, 'entity': 'LABEL_0', 'index': 254, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9995821118354797, 'entity': 'LABEL_0', 'index': 255, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9994851350784302, 'entity': 'LABEL_0', 'index': 256, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.999489426612854, 'entity': 'LABEL_0', 'index': 257, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9995247721672058, 'entity': 'LABEL_0', 'index': 258, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9993212223052979, 'entity': 'LABEL_0', 'index': 259, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.999346911907196, 'entity': 'LABEL_0', 'index': 260, 'start': None, 'end': None}\n",
      "{'word': 'Y', 'score': 0.9990231394767761, 'entity': 'LABEL_0', 'index': 261, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9995079040527344, 'entity': 'LABEL_0', 'index': 262, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9992209076881409, 'entity': 'LABEL_0', 'index': 263, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.999557614326477, 'entity': 'LABEL_0', 'index': 264, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.9991567134857178, 'entity': 'LABEL_0', 'index': 265, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9989147782325745, 'entity': 'LABEL_0', 'index': 266, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9987962245941162, 'entity': 'LABEL_0', 'index': 267, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9980782866477966, 'entity': 'LABEL_0', 'index': 268, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9952538013458252, 'entity': 'LABEL_0', 'index': 269, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.994080662727356, 'entity': 'LABEL_0', 'index': 270, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9980298280715942, 'entity': 'LABEL_0', 'index': 271, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9955498576164246, 'entity': 'LABEL_0', 'index': 272, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9914674162864685, 'entity': 'LABEL_0', 'index': 273, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9929232001304626, 'entity': 'LABEL_0', 'index': 274, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.895211935043335, 'entity': 'LABEL_0', 'index': 275, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.99253910779953, 'entity': 'LABEL_0', 'index': 276, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9623369574546814, 'entity': 'LABEL_0', 'index': 277, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9963775873184204, 'entity': 'LABEL_0', 'index': 278, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9697791337966919, 'entity': 'LABEL_0', 'index': 279, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9738325476646423, 'entity': 'LABEL_0', 'index': 280, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.930341362953186, 'entity': 'LABEL_0', 'index': 281, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.8387477397918701, 'entity': 'LABEL_0', 'index': 282, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.8152205348014832, 'entity': 'LABEL_0', 'index': 283, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9806275367736816, 'entity': 'LABEL_0', 'index': 284, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9528396129608154, 'entity': 'LABEL_0', 'index': 285, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9502189755439758, 'entity': 'LABEL_0', 'index': 286, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9372878670692444, 'entity': 'LABEL_0', 'index': 287, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9678199887275696, 'entity': 'LABEL_0', 'index': 288, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9798095226287842, 'entity': 'LABEL_0', 'index': 289, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9765522480010986, 'entity': 'LABEL_0', 'index': 290, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9802826046943665, 'entity': 'LABEL_0', 'index': 291, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9837402701377869, 'entity': 'LABEL_0', 'index': 292, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9784964323043823, 'entity': 'LABEL_0', 'index': 293, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.982938826084137, 'entity': 'LABEL_0', 'index': 294, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9613761901855469, 'entity': 'LABEL_0', 'index': 295, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9944359660148621, 'entity': 'LABEL_0', 'index': 296, 'start': None, 'end': None}\n",
      "{'word': 'D', 'score': 0.997485339641571, 'entity': 'LABEL_0', 'index': 297, 'start': None, 'end': None}\n",
      "{'word': 'N', 'score': 0.9846292734146118, 'entity': 'LABEL_0', 'index': 298, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9787927865982056, 'entity': 'LABEL_0', 'index': 299, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9896279573440552, 'entity': 'LABEL_0', 'index': 300, 'start': None, 'end': None}\n",
      "{'word': 'L', 'score': 0.9944964647293091, 'entity': 'LABEL_0', 'index': 301, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9973328113555908, 'entity': 'LABEL_0', 'index': 302, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9988123178482056, 'entity': 'LABEL_0', 'index': 303, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9971795082092285, 'entity': 'LABEL_0', 'index': 304, 'start': None, 'end': None}\n",
      "{'word': 'Q', 'score': 0.9990347623825073, 'entity': 'LABEL_0', 'index': 305, 'start': None, 'end': None}\n",
      "{'word': 'H', 'score': 0.9983610510826111, 'entity': 'LABEL_0', 'index': 306, 'start': None, 'end': None}\n",
      "{'word': 'E', 'score': 0.9993875026702881, 'entity': 'LABEL_0', 'index': 307, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9978039860725403, 'entity': 'LABEL_0', 'index': 308, 'start': None, 'end': None}\n",
      "{'word': 'I', 'score': 0.9994252920150757, 'entity': 'LABEL_0', 'index': 309, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9991670846939087, 'entity': 'LABEL_0', 'index': 310, 'start': None, 'end': None}\n",
      "{'word': 'M', 'score': 0.9993822574615479, 'entity': 'LABEL_0', 'index': 311, 'start': None, 'end': None}\n",
      "{'word': 'H', 'score': 0.9957172274589539, 'entity': 'LABEL_0', 'index': 312, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9993754625320435, 'entity': 'LABEL_0', 'index': 313, 'start': None, 'end': None}\n",
      "{'word': 'X', 'score': 0.9995155930519104, 'entity': 'LABEL_0', 'index': 314, 'start': None, 'end': None}\n",
      "{'word': 'X', 'score': 0.9994916319847107, 'entity': 'LABEL_0', 'index': 315, 'start': None, 'end': None}\n",
      "{'word': 'X', 'score': 0.9995693564414978, 'entity': 'LABEL_0', 'index': 316, 'start': None, 'end': None}\n",
      "{'word': 'X', 'score': 0.9991987943649292, 'entity': 'LABEL_0', 'index': 317, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.997605562210083, 'entity': 'LABEL_0', 'index': 318, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9991939663887024, 'entity': 'LABEL_0', 'index': 319, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.998712956905365, 'entity': 'LABEL_0', 'index': 320, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9986796379089355, 'entity': 'LABEL_0', 'index': 321, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.999178946018219, 'entity': 'LABEL_0', 'index': 322, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9993354678153992, 'entity': 'LABEL_0', 'index': 323, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9970476627349854, 'entity': 'LABEL_0', 'index': 324, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9923351407051086, 'entity': 'LABEL_0', 'index': 325, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9991627335548401, 'entity': 'LABEL_0', 'index': 326, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9654111862182617, 'entity': 'LABEL_0', 'index': 327, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9983397126197815, 'entity': 'LABEL_0', 'index': 328, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9824903011322021, 'entity': 'LABEL_0', 'index': 329, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.9969463348388672, 'entity': 'LABEL_0', 'index': 330, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9964633584022522, 'entity': 'LABEL_0', 'index': 331, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9838727712631226, 'entity': 'LABEL_0', 'index': 332, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9759439826011658, 'entity': 'LABEL_0', 'index': 333, 'start': None, 'end': None}\n",
      "{'word': 'C', 'score': 0.9977365732192993, 'entity': 'LABEL_0', 'index': 334, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9991732239723206, 'entity': 'LABEL_0', 'index': 335, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9990852475166321, 'entity': 'LABEL_0', 'index': 336, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9993051886558533, 'entity': 'LABEL_0', 'index': 337, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9989097714424133, 'entity': 'LABEL_0', 'index': 338, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.994024395942688, 'entity': 'LABEL_0', 'index': 339, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9978886246681213, 'entity': 'LABEL_0', 'index': 340, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9987389445304871, 'entity': 'LABEL_0', 'index': 341, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9991274476051331, 'entity': 'LABEL_0', 'index': 342, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9926390051841736, 'entity': 'LABEL_0', 'index': 343, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9784454107284546, 'entity': 'LABEL_0', 'index': 344, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.999260663986206, 'entity': 'LABEL_0', 'index': 345, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9972747564315796, 'entity': 'LABEL_0', 'index': 346, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9993363618850708, 'entity': 'LABEL_0', 'index': 347, 'start': None, 'end': None}\n",
      "{'word': 'C', 'score': 0.9982907176017761, 'entity': 'LABEL_0', 'index': 348, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9990900754928589, 'entity': 'LABEL_0', 'index': 349, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9973540306091309, 'entity': 'LABEL_0', 'index': 350, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9988422393798828, 'entity': 'LABEL_0', 'index': 351, 'start': None, 'end': None}\n",
      "{'word': 'K', 'score': 0.9853236675262451, 'entity': 'LABEL_0', 'index': 352, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9934561848640442, 'entity': 'LABEL_0', 'index': 353, 'start': None, 'end': None}\n",
      "{'word': 'V', 'score': 0.9962758421897888, 'entity': 'LABEL_0', 'index': 354, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9948272109031677, 'entity': 'LABEL_0', 'index': 355, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9986714124679565, 'entity': 'LABEL_0', 'index': 356, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9917215704917908, 'entity': 'LABEL_0', 'index': 357, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9980403780937195, 'entity': 'LABEL_0', 'index': 358, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9886158108711243, 'entity': 'LABEL_0', 'index': 359, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9798068404197693, 'entity': 'LABEL_0', 'index': 360, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9642913341522217, 'entity': 'LABEL_0', 'index': 361, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9994303584098816, 'entity': 'LABEL_0', 'index': 362, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9719095826148987, 'entity': 'LABEL_0', 'index': 363, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9887797236442566, 'entity': 'LABEL_0', 'index': 364, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9869307279586792, 'entity': 'LABEL_0', 'index': 365, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9950433969497681, 'entity': 'LABEL_0', 'index': 366, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9981550574302673, 'entity': 'LABEL_0', 'index': 367, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.99593186378479, 'entity': 'LABEL_0', 'index': 368, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.996087372303009, 'entity': 'LABEL_0', 'index': 369, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9997151494026184, 'entity': 'LABEL_0', 'index': 370, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9997242093086243, 'entity': 'LABEL_0', 'index': 371, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9975329041481018, 'entity': 'LABEL_0', 'index': 372, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9995861649513245, 'entity': 'LABEL_0', 'index': 373, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9996209144592285, 'entity': 'LABEL_0', 'index': 374, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9944046139717102, 'entity': 'LABEL_0', 'index': 375, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9984874725341797, 'entity': 'LABEL_0', 'index': 376, 'start': None, 'end': None}\n",
      "{'word': 'W', 'score': 0.9976655840873718, 'entity': 'LABEL_0', 'index': 377, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9866195917129517, 'entity': 'LABEL_0', 'index': 378, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9984613656997681, 'entity': 'LABEL_0', 'index': 379, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9981020092964172, 'entity': 'LABEL_0', 'index': 380, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9986013174057007, 'entity': 'LABEL_0', 'index': 381, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9991669058799744, 'entity': 'LABEL_0', 'index': 382, 'start': None, 'end': None}\n",
      "{'word': 'W', 'score': 0.9990222454071045, 'entity': 'LABEL_0', 'index': 383, 'start': None, 'end': None}\n",
      "{'word': 'H', 'score': 0.9981220960617065, 'entity': 'LABEL_0', 'index': 384, 'start': None, 'end': None}\n",
      "{'word': 'W', 'score': 0.9992678165435791, 'entity': 'LABEL_0', 'index': 385, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9989079833030701, 'entity': 'LABEL_0', 'index': 386, 'start': None, 'end': None}\n",
      "{'word': 'C', 'score': 0.9991226196289062, 'entity': 'LABEL_0', 'index': 387, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9985209107398987, 'entity': 'LABEL_0', 'index': 388, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9992786049842834, 'entity': 'LABEL_0', 'index': 389, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9990835189819336, 'entity': 'LABEL_0', 'index': 390, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9979631304740906, 'entity': 'LABEL_0', 'index': 391, 'start': None, 'end': None}\n",
      "{'word': 'W', 'score': 0.9992745518684387, 'entity': 'LABEL_0', 'index': 392, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9994053840637207, 'entity': 'LABEL_0', 'index': 393, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9991880655288696, 'entity': 'LABEL_0', 'index': 394, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9985659718513489, 'entity': 'LABEL_0', 'index': 395, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9989712834358215, 'entity': 'LABEL_0', 'index': 396, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9975546002388, 'entity': 'LABEL_0', 'index': 397, 'start': None, 'end': None}\n",
      "{'word': 'T', 'score': 0.9949931502342224, 'entity': 'LABEL_0', 'index': 398, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9965153336524963, 'entity': 'LABEL_0', 'index': 399, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9919061064720154, 'entity': 'LABEL_0', 'index': 400, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9965653419494629, 'entity': 'LABEL_0', 'index': 401, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9980343580245972, 'entity': 'LABEL_0', 'index': 402, 'start': None, 'end': None}\n",
      "{'word': 'R', 'score': 0.9956786632537842, 'entity': 'LABEL_0', 'index': 403, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.996499240398407, 'entity': 'LABEL_0', 'index': 404, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9952534437179565, 'entity': 'LABEL_0', 'index': 405, 'start': None, 'end': None}\n",
      "{'word': 'G', 'score': 0.9956422448158264, 'entity': 'LABEL_0', 'index': 406, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9958911538124084, 'entity': 'LABEL_0', 'index': 407, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9952825903892517, 'entity': 'LABEL_0', 'index': 408, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9992682337760925, 'entity': 'LABEL_0', 'index': 409, 'start': None, 'end': None}\n",
      "{'word': 'S', 'score': 0.9991005659103394, 'entity': 'LABEL_0', 'index': 410, 'start': None, 'end': None}\n",
      "{'word': 'P', 'score': 0.9989532232284546, 'entity': 'LABEL_0', 'index': 411, 'start': None, 'end': None}\n",
      "{'word': 'A', 'score': 0.9996453523635864, 'entity': 'LABEL_0', 'index': 412, 'start': None, 'end': None}\n"
     ]
    }
   ],
   "source": [
    "testdict = meatpipe(test_sequence, max_length=512)\n",
    "for i in testdict:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.93 GiB (GPU 0; 15.75 GiB total capacity; 13.31 GiB already allocated; 1.69 GiB free; 13.33 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-32a78f3463fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_IDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#preds = torch.max(preds, 1).indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(preds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8d5c74774cfa>\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, input_ids, attention_mask, return_logits)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_logits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         )\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m         )\n\u001b[1;32m    983\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m                 )\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m         )\n\u001b[1;32m    463\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         )\n\u001b[1;32m    396\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnabert/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.93 GiB (GPU 0; 15.75 GiB total capacity; 13.31 GiB already allocated; 1.69 GiB free; 13.33 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "preds = model.predict_classes(in_IDS, att_mask, return_logits=True)\n",
    "#preds = torch.max(preds, 1).indices\n",
    "# print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#parses through each validation sample and gets logits and compiles into a masterList of metrics\n",
    "\n",
    "masterList = []\n",
    "\n",
    "\n",
    "for singleSample in range(len(preds)):\n",
    "#   ======================  \n",
    "    def labelLabel(labels):\n",
    "        labels = labels.tolist()\n",
    "        trueList = []\n",
    "\n",
    "        previous = 0\n",
    "        for lab in labels:\n",
    "            if lab == -100:\n",
    "                trueList.append(previous)\n",
    "            else:\n",
    "                previous = lab\n",
    "                trueList.append(previous)\n",
    "        return trueList\n",
    "    \n",
    "    def domainAcc(true_label, predict):  # finds the start and stop of the actual sequence (range style where stop is actually stop - 1)\n",
    "        switch = False\n",
    "        start = 0\n",
    "        stop = len(true_label)\n",
    "        counter = 1\n",
    "        true_label = true_label\n",
    "        domainLabel = None\n",
    "        numCorrectLabels = 0\n",
    "        numNotLabels = 0\n",
    "\n",
    "        \n",
    "        for i in true_label:\n",
    "            if int(i) != 0 and switch == False:\n",
    "                switch = True\n",
    "                start = counter\n",
    "            elif int(i) == 0 and switch == True:\n",
    "                stop = counter - 1\n",
    "                break\n",
    "            counter += 1\n",
    "        \n",
    "        numInDomain = stop - (start - 1)\n",
    "        \n",
    "        for i in true_label:\n",
    "            if i != 0:\n",
    "                domainLabel = i\n",
    "\n",
    "        for i in predict[start - 1:stop]:\n",
    "            if i == domainLabel:\n",
    "                numCorrectLabels += 1\n",
    "            \n",
    "        domainLabelAcc = numCorrectLabels/numInDomain\n",
    "        \n",
    "        for i in predict[:start - 1]:\n",
    "            if i == 0:\n",
    "                numNotLabels += 1\n",
    "        \n",
    "        for i in predict[stop - 1:]:\n",
    "            if i == 0:\n",
    "                numNotLabels += 1\n",
    "        \n",
    "        numNotInDomain = len(true_label) - numInDomain\n",
    "        notDomainLabelAcc = numNotLabels/numNotInDomain\n",
    "        \n",
    "        return [start, stop, domainLabelAcc, notDomainLabelAcc]\n",
    "    \n",
    "    def evaluate_positions(true, predict):\n",
    "        switch1 = True\n",
    "        switch2 = True\n",
    "        predStart = None\n",
    "        trueStart = 0\n",
    "        predStop = None\n",
    "        trueStop = 0\n",
    "        counter = 0\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(len(true)):\n",
    "\n",
    "            if true[i] != 0 and switch2:\n",
    "                switch2 = False\n",
    "                trueStart = i\n",
    "#                 print(f\"REAL START POSITION {trueStart}\")\n",
    "\n",
    "            if predict[i] != 0 and switch1:\n",
    "                switch1 = False\n",
    "                predStart = i\n",
    "#                 print(f\"PRED START POSITION {predStart}\")\n",
    "\n",
    "            if true[i] == 0 and switch2 == False:\n",
    "                switch2 = None\n",
    "                trueStop = i - 1\n",
    "#                 print(f\"REAL STOP POSITION {trueStop}\")\n",
    "\n",
    "            if predict[i] == 0 and switch1 == False:\n",
    "                switch1 = None\n",
    "                predStop = i - 1\n",
    "#                 print(f\"PRED STOP POSITION {predStop}\")\n",
    "\n",
    "#             if predict[i] != true[i]:\n",
    "#                 print(f\"{counter}) {true[i]}|=|{predict[i]} >> NOT\")\n",
    "#             else:\n",
    "#                 print(f\"{counter}) {true[i]}|=|{predict[i]}\")\n",
    "            counter += 1\n",
    "        \n",
    "        \n",
    "        return (trueStart, trueStop, predStart, predStop)\n",
    "    \n",
    "    def matching_labels(true, predict, domainStart, domainStop):\n",
    "        trueList = []\n",
    "        predictListDomain = []\n",
    "        predictListNotdomain = []\n",
    "        true = true\n",
    "        predict = predict.tolist()\n",
    "        for label in true:\n",
    "            trueList.append(label)\n",
    "            \n",
    "        for label in predict[domainStart:domainStop]:\n",
    "            predictListDomain.append(label)\n",
    "            \n",
    "        for label in predict[:domainStart + 1]:\n",
    "            predictListNotdomain.append(label)\n",
    "        for label in predict[domainStop: ]:\n",
    "            predictListNotdomain.append(label)\n",
    "            \n",
    "        trueList = set(trueList)\n",
    "        trueList = list(trueList)\n",
    "        predictListDomain = set(predictListDomain)\n",
    "        predictListDomain = list(predictListDomain)\n",
    "        predictListNotdomain = set(predictListNotdomain)\n",
    "        predictListNotdomain = list(predictListNotdomain)\n",
    "        \n",
    "        return (trueList, predictListDomain, predictListNotdomain)\n",
    "    \n",
    "#   ======================\n",
    "    fullDataDict = {}\n",
    "    labelDataDict = {}\n",
    "    predict = torch.max(preds[singleSample], 1).indices\n",
    "    true = labelLabel(encoded_test[singleSample][\"labels\"])\n",
    "    domainAccuracy = domainAcc(true, predict)\n",
    "    acc_start = domainAccuracy[0]\n",
    "    acc_stop = domainAccuracy[1]\n",
    "    domain_accuracy = domainAccuracy[2]\n",
    "    notDomain_accuracy = domainAccuracy[3]\n",
    "    positions = evaluate_positions(true, predict)\n",
    "    trueStart = positions[0]\n",
    "    trueStop = positions[1]\n",
    "    predStart = positions[2]\n",
    "    predStop = positions[3]\n",
    "    domainStart = acc_start = 1\n",
    "    domainStop = acc_stop\n",
    "    match_label = matching_labels(true, predict, domainStart, domainStop)\n",
    "    labelsInTrue = match_label[0]\n",
    "    labelsInPredDomain = match_label[1]\n",
    "    labelsInPredNotdomain = match_label[2]\n",
    "    start_site = 0\n",
    "    stop_site = 0\n",
    "    attentionLabel = None\n",
    "    \n",
    "    for i in labelsInTrue:\n",
    "        if i != 0:\n",
    "            attentionLabel = i\n",
    "    \n",
    "#     print(f\"start: {acc_start}, stop: {acc_stop}, domain accuracy: {domain_accuracy}, not domain accuracy: {notDomain_accuracy}\")\n",
    "    \n",
    "#     print(f\"trueList labels: {labelsInTrue}\")\n",
    "#     print(f\"predictListDomain: {labelsInPredDomain}\")\n",
    "#     print(f\"predictListNotdomain: {labelsInPredNotdomain}\")\n",
    "    \n",
    "    \n",
    "#     if trueStart == predStart:\n",
    "#         print(f\"START SITE ACCURATE\")\n",
    "#         start_site = 1\n",
    "#     else:\n",
    "#         print(f\"START SITE INACCURATE\")\n",
    "#     print(f\"TRUE START: {trueStart} || {trueStop} :TRUE STOP\")\n",
    "#     if trueStop == predStop:\n",
    "#         print(f\"STOP SITE ACCURATE\")\n",
    "#         stop_site = 1\n",
    "#     else:\n",
    "#         print(f\"STOP SITE INACCURATE\")\n",
    "#     print(f\"PRED START: {predStart} || {predStop} :PRED STOP\")\n",
    "\n",
    "#     print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "    \n",
    "    \"\"\"\n",
    "    1) domain accuracy\n",
    "    2) not domain accuracy\n",
    "    3) start site accuracy\n",
    "    4) stop site accuracy\n",
    "    5) labels in true domain\n",
    "    6) labels in pred domain\n",
    "    7) labels in pred not domain\n",
    "    \"\"\"\n",
    "    fullDataDict[\"domain_accuracy\"] = domain_accuracy\n",
    "    fullDataDict[\"notDomain_accuracy\"] = notDomain_accuracy\n",
    "    fullDataDict[\"start_site\"] = start_site\n",
    "    fullDataDict[\"stop_site\"] = stop_site\n",
    "    fullDataDict[\"trueLabels\"] = labelsInTrue\n",
    "    fullDataDict[\"predDomainLabels\"] = labelsInPredDomain\n",
    "    fullDataDict[\"predNotdomainLabels\"] = labelsInPredNotdomain\n",
    "    \n",
    "    labelDataDict[attentionLabel] = fullDataDict\n",
    "    masterList.append(labelDataDict)\n",
    "    \n",
    "\"\"\"\n",
    "1. check to see if start site matches, and also check if it labelled anything else before start site wrong too\n",
    "2. check to see if end site matches, also check if it labelled anything else after stop site wrong too\n",
    "3. check middle to see if it is all filled, also check if its all same label\n",
    "\n",
    "4. evaluate based on % of correct labels inside of domain\n",
    "5. also evaluate based on % of correct labels outside of domain\n",
    "\n",
    "6. then after getting percentages for each sample, evaluate based on the domains (group metrics by domains and average those)\n",
    "7. see what types of labels are predicted to be inside the domain, and also see what types of labels are predicted to be outisde the domain\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, -100, -100, 59, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
      "        59, 59, 59, 59,  0, 59, 59,  0, 59, 59,  0,  0,  0,  0,  0,  0,  0, 59,\n",
      "        59,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        59, 59,  0,  0,  0,  0, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
      "        59, 59, 59, 59, 59, 59, 59, 59,  0, 59,  0,  0,  0,  0,  0,  0, 59, 59,\n",
      "         0,  0,  0, 59, 59, 59, 59, 59, 59, 59,  0,  0, 59, 59, 59, 59, 59, 59,\n",
      "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,  0,  0, 59, 59,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 59,\n",
      "        59,  0, 59,  0, 59,  0, 59, 59, 59, 59,  0, 59, 59, 59, 59,  0, 59,  0,\n",
      "         0,  0,  0,  0,  0,  0, 59,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0, 59,  0, 59, 59, 59, 59, 59, 59,  0,\n",
      "        59, 59, 59, 59, 59, 59,  0, 59, 59,  0,  0,  0, 59,  0,  0,  0,  0,  0,\n",
      "         0, 59,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 4, stop: 77, domain accuracy: 0.33783783783783783, not domain accuracy: 0.8105022831050228\n",
      "trueList labels: [0, 59]\n",
      "predictListDomain: [0, 59]\n",
      "predictListNotdomain: [0, 59]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 3 || 76 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 21 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[0, -100, -100, -100, -100, -100, -100, 33, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33]\n",
      "tensor([ 0, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,  0, 33,\n",
      "        33, 33,  0,  0,  0,  0,  0,  0,  0,  0,  0, 33,  0, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33,  0, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33,  0, 33, 33, 33,  0, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33,  0,  0, 33,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0, 33, 33, 33, 33,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 33,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0, 33,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0, 33,  0,  0,  0,  0, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33,  0, 33, 33, 33, 33, 33,  0,  0, 33, 33, 33, 33, 33,  0,  0,  0,  0,\n",
      "        33,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 8, stop: 512, domain accuracy: 0.49504950495049505, not domain accuracy: 0.2857142857142857\n",
      "trueList labels: [0, 33]\n",
      "predictListDomain: [0, 33]\n",
      "predictListNotdomain: [0, 33]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 7 || 512 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 159 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "0/107567\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 33, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "         5, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33,  0,  0,  0,  0, 33,  0, 33, 33, 33,  0, 33,\n",
      "        33, 33,  0, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,  0,  0,  0, 33,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0, 33, 33, 33, 33, 33,  0,  0,  0,  0,  0,  0,  0,\n",
      "        33,  0, 33,  0, 33, 33,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 29, stop: 451, domain accuracy: 0.3947990543735225, not domain accuracy: 0.7078651685393258\n",
      "trueList labels: [0, 33]\n",
      "predictListDomain: [0, 33]\n",
      "predictListNotdomain: [0, 33, 5]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 28 || 450 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 150 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, 23, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,  0, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23,  0,  0,  0,  0,  0,  0, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 23,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0, 23, 23, 23,  0,  0,  0,  0, 23, 23,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0, 23, 23,  0,  0,  0,  0,  0, 23,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 11, stop: 300, domain accuracy: 0.2517241379310345, not domain accuracy: 0.9279279279279279\n",
      "trueList labels: [0, 23]\n",
      "predictListDomain: [0, 23]\n",
      "predictListNotdomain: [0, 23]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 10 || 299 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 28 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "2/107567\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 23, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,  0, 23,\n",
      "         0, 23, 23, 23, 23, 23,  0, 23, 23, 23, 23,  0,  0, 23, 23,  0, 23, 23,\n",
      "         0, 23, 23, 23, 23, 23, 23,  0,  0,  0,  0,  0,  0, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23,  0, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,  0,  0,  0,  0,  0,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23,  0, 23,  0,  0,  0,  0, 23, 23,  0, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 23, 23,\n",
      "        23,  0, 23,  0, 23, 23,  0, 23, 23, 23,  0, 23,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 78, stop: 378, domain accuracy: 0.34551495016611294, not domain accuracy: 0.7061611374407583\n",
      "trueList labels: [0, 23]\n",
      "predictListDomain: [0, 23]\n",
      "predictListNotdomain: [0, 23]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 77 || 377 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 33 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[0, -100, -100, -100, -100, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2,\n",
      "        2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:1')\n",
      "start: 6, stop: 296, domain accuracy: 0.3333333333333333, not domain accuracy: 0.9592760180995475\n",
      "trueList labels: [0, 2]\n",
      "predictListDomain: [0, 2]\n",
      "predictListNotdomain: [0, 2]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 5 || 295 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 31 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "4/107567\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 49, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0,  0, 23,  0, 23, 23,  0,  0,  0,  0,  0,  0, 23,  0,  0, 23, 23,  0,\n",
      "         0,  0,  0, 49,  0,  0,  0,  0,  0,  0,  0,  0,  0, 49, 49, 49,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0, 49, 49, 49, 49,  0,  0,  0, 49,  0,  0, 49, 49, 49, 49, 49,\n",
      "         0,  0,  0,  0, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,\n",
      "        49, 49, 49, 49, 49, 49, 49, 49, 49,  0, 49, 49, 49,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 49,\n",
      "         0, 49, 49, 49,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 49,  0, 49, 49,\n",
      "         0, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0, 49,  0,  0,  0,  0, 49, 49, 49,  0,  0,  0,  0,\n",
      "         0, 49, 49, 49,  0, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,\n",
      "        49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0, 49, 49, 49,  0,  0,  0,  0,  0,  0, 49, 49, 49, 49,\n",
      "        49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,  0, 49, 49,  0, 49,\n",
      "         0, 49, 49, 49,  0, 49,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 131, stop: 232, domain accuracy: 0.2549019607843137, not domain accuracy: 0.7585365853658537\n",
      "trueList labels: [0, 49]\n",
      "predictListDomain: [0, 49]\n",
      "predictListNotdomain: [0, 49, 23]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 130 || 231 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 2 || 2 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 59, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 59,  0,  0,  0,  0,  0, 59,  0, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
      "        59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
      "        59, 59, 59, 59,  0, 59, 59,  0, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 23,\n",
      "         0,  0,  0,  0,  0, 23,  0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23,  0, 23, 23, 23, 23, 23,  0,  0,  0, 23,  0, 23,  0,\n",
      "         0,  0, 23, 23, 23, 23, 23, 23, 23,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0, 23,  0,  0,  0,  0, 23, 23,  0,  0, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0, 23,  0,  0, 23,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 23, stop: 91, domain accuracy: 0.43478260869565216, not domain accuracy: 0.8510158013544018\n",
      "trueList labels: [0, 59]\n",
      "predictListDomain: [0, 59]\n",
      "predictListNotdomain: [0, 59, 5, 23]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 22 || 90 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 1 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "6/107567\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 32, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 28, 28, 28, 28, 28, 28, 32, 28, 28, 28, 28, 32, 28, 32, 28, 32, 32,\n",
      "        32, 32, 32, 32,  5,  0,  0, 32,  5,  0, 28, 32,  0,  0,  0, 32,  0,  0,\n",
      "         0, 32, 28,  0,  0, 28, 28, 28, 32, 28, 32, 32, 32, 28, 32, 32, 28, 32,\n",
      "        32, 32, 32, 32, 32, 32, 28, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 28, 28, 28, 28, 28, 28, 28,\n",
      "        28, 28, 28, 28, 28, 28, 28, 28, 28, 32, 32, 32, 32, 28, 32, 28, 32, 32,\n",
      "         0,  5,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 28, 28,  0,  0, 28, 32,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
      "        32, 32,  0,  0,  0,  0,  0,  0,  0, 28, 28, 28, 32, 28,  0,  5,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0, 28, 28, 28, 28, 28, 28,  0,  0, 32, 32, 32,\n",
      "        32, 32, 32,  0,  0, 32,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0, 32, 32, 32, 32, 32, 32,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32,  0, 32,  0, 32,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0, 32,  0,  0,  0,  0,  0,  0, 32, 32,  0,  0,  0, 32,\n",
      "         0, 32, 32, 32, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 32,\n",
      "         0, 32,  0, 32, 32, 32, 32, 32, 32, 32,  0, 32, 32, 32,  0, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0, 32,  0,  0,  0,  0, 32,  0, 32,  0, 32,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 268, stop: 452, domain accuracy: 0.25405405405405407, not domain accuracy: 0.5351681957186545\n",
      "trueList labels: [0, 32]\n",
      "predictListDomain: [32, 0]\n",
      "predictListNotdomain: [0, 32, 28, 5]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 267 || 451 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 22 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 23, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 23, 23, 23, 23, 23, 23, 23, 23,  0, 23, 23, 23, 23, 23,  0, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23,  0, 23, 23, 23,  0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,  0, 23,\n",
      "        23, 23,  0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23,  0, 23, 23, 23,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0, 23,  0, 23,  0, 23,  0,  0,  0,  0,  0,  0, 23,  0,  0,  0,\n",
      "         0, 23,  0,  0,  0,  0,  0,  0,  0,  0,  0, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23,  0,  0,  0,  0, 23, 23, 23, 23,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  5,  0,  0,  0,  5,  0,  0,  5,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 68, stop: 368, domain accuracy: 0.34551495016611294, not domain accuracy: 0.6919431279620853\n",
      "trueList labels: [0, 23]\n",
      "predictListDomain: [0, 23]\n",
      "predictListNotdomain: [0, 5, 23]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 67 || 367 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 8 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "8/107567\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 40, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 54,  0, 40,  0,  0,  0,  0,  0, 54,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0, 40, 40, 40, 40, 40,  0,  0,  0, 40, 40, 40, 40, 40, 40, 40,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40, 40, 40, 40,  0, 40,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40,  0, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        40,  0,  0,  0,  0, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "         0, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 40, 40, 40,\n",
      "        40, 40,  0, 40, 40, 40, 40, 40, 40, 40, 40,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0, 40,  0, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 13, stop: 48, domain accuracy: 0.2777777777777778, not domain accuracy: 0.7436974789915967\n",
      "trueList labels: [0, 40]\n",
      "predictListDomain: [40, 0, 54]\n",
      "predictListNotdomain: [0, 40]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 12 || 47 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 21 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 59, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 21, 21, 21, 21, 10, 21, 21, 32, 32, 32, 32, 32, 19, 19, 19, 19, 24,\n",
      "        24, 24, 10, 24,  5, 24, 24, 24,  0,  0,  0,  0,  0,  0,  0, 24, 24, 24,\n",
      "        24, 24,  0,  3,  0,  0,  0, 24, 24, 24,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "        24,  0, 54,  3,  5,  5,  5,  5,  5,  5,  5,  5,  3,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 58,  0,  5,  0,  0,  0,  0, 59,\n",
      "         0, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59,  0,  0, 54,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0, 59,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0, 59,  0, 59,  0,  0,  0,  0,  0,  0, 59, 59, 59,\n",
      "        59, 59,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 188, stop: 220, domain accuracy: 0.15151515151515152, not domain accuracy: 0.8455114822546973\n",
      "trueList labels: [0, 59]\n",
      "predictListDomain: [0, 59, 54]\n",
      "predictListNotdomain: [0, 32, 3, 5, 10, 19, 21, 54, 24, 58, 59]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 187 || 219 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 25 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "10/107567\n",
      "[0, -100, -100, -100, -100, -100, 33, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,  0, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 33,  0,  0,  0,  0,  0,  0,  0, 33,  0,  0,  0,  0,  0, 33,\n",
      "        33, 33, 33, 33, 33, 33,  0,  0,  0, 33, 33,  0,  0,  0,  0, 33,  0, 33,\n",
      "        33, 33,  0, 33, 33,  0,  0,  0,  0, 33, 33, 33,  0, 33,  0, 33, 33, 33,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0, 33,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0, 33,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0, 33,  0,  0,  0, 33,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0, 33, 33,  0,  0, 33,  0, 33, 33, 33,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 7, stop: 411, domain accuracy: 0.4666666666666667, not domain accuracy: 0.8691588785046729\n",
      "trueList labels: [0, 33]\n",
      "predictListDomain: [0, 33]\n",
      "predictListNotdomain: [0, 33]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 6 || 410 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 118 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[46, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46]\n",
      "tensor([46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
      "        46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
      "        46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
      "        46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
      "        46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
      "        46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
      "        46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
      "        46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
      "        46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
      "        46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
      "        46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,  0, 46, 46, 46, 46,\n",
      "        46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
      "        46, 46,  0,  0,  0,  0,  0,  0, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
      "        46, 46, 46, 46,  0, 46, 46,  0, 46, 46, 46, 46,  0,  0, 46,  0,  0,  0,\n",
      "         0, 46,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 1, stop: 512, domain accuracy: 0.466796875, not domain accuracy: 0.001953125\n",
      "trueList labels: [46]\n",
      "predictListDomain: [0, 46]\n",
      "predictListNotdomain: [46]\n",
      "START SITE ACCURATE\n",
      "TRUE START: 0 || 512 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 0 || 192 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "12/107567\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 32, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 28, 28, 32, 32, 28, 32,  0,  0,  0,  0,  0,  0, 28,  0,  0,  0,  0,\n",
      "         0,  0,  0, 28,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 32,  0,  0,  0,\n",
      "         0, 32, 32, 32, 32,  0,  0,  0,  0, 32,  0,  0,  0, 32,  0, 32, 32, 28,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,  0,  0,\n",
      "         0, 32, 32,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0, 32, 28, 28,  0, 28, 32,  0,  0,  0,  0,  0,  0, 32, 32, 32, 32,  0,\n",
      "         0,  0,  0,  0, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0, 32, 32, 32, 28, 28, 28, 28, 28, 28, 28, 28,  0, 28, 28, 28,\n",
      "         0, 28,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0, 32, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        28, 28, 28,  0, 28,  0, 28,  0,  0,  0,  0,  0,  0,  0, 32,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 32, 32, 32,  0, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32,  0,  0,  0,  0,  0,  0, 32,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0, 32, 32, 32, 32, 32, 32, 32, 32,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0, 32, 32,  0, 32,  0,  0, 32,  0, 32, 32, 32, 32, 32,  0,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,  0, 32, 32, 32,\n",
      "         0, 32, 32,  0, 32, 32,  0,  0,  0, 32,  0,  0,  0,  0,  0, 32, 32, 32,\n",
      "        32, 32, 32, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        32, 32, 32,  0,  0,  0,  0,  0, 32, 32, 32, 32, 32, 32, 32,  0,  0, 32,\n",
      "        32, 32,  0, 32, 32, 32, 32, 32, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0, 32, 32, 32,  0,  0, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32,  0,  0,  0,  0,  0,  0, 32, 32,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 291, stop: 470, domain accuracy: 0.36666666666666664, not domain accuracy: 0.6295180722891566\n",
      "trueList labels: [0, 32]\n",
      "predictListDomain: [32, 0]\n",
      "predictListNotdomain: [0, 32, 28, 5]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 290 || 469 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 6 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 23, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23,  0, 23, 23,  0,  0, 23, 23, 23, 23, 23, 23, 23, 23, 23,  0,\n",
      "         0, 23, 23,  0, 23,  0,  0,  0, 23,  0, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23,  0,  0,  0,  0,  0,  0,  0,  0, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23,  0,  0,  0,  0, 23, 23, 23, 23, 23, 23,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 23,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0, 23,  0, 23, 23,  5,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  0,  5,\n",
      "         0,  0,  0,  5,  5,  0,  0,  0,  5,  5,  0,  0,  0,  0,  0,  0,  5,  0,\n",
      "         0,  5,  5,  0,  0,  5,  5,  0,  0,  0,  0,  0,  5,  0,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  0,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  0], device='cuda:1')\n",
      "start: 15, stop: 316, domain accuracy: 0.4304635761589404, not domain accuracy: 0.5761904761904761\n",
      "trueList labels: [0, 23]\n",
      "predictListDomain: [0, 5, 23]\n",
      "predictListNotdomain: [0, 5, 23]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 14 || 315 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 92 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "14/107567\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 39, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39]\n",
      "tensor([ 0, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39,  0,  0,  0, 39,  0,  0,  0, 39,  0, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 39,  0,  0,  0,  0,  0,\n",
      "         0, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
      "        39,  0, 39, 39, 39,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 30, stop: 512, domain accuracy: 0.20910973084886128, not domain accuracy: 0.06896551724137931\n",
      "trueList labels: [0, 39]\n",
      "predictListDomain: [0, 39]\n",
      "predictListNotdomain: [0, 39]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 29 || 512 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 58 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 23, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23,  0, 23, 23, 23, 23, 23, 23, 23,  0, 23, 23, 23,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 23, 23,  0, 23, 23, 23,  0,\n",
      "        23,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  5,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  5,  0,  0,  0,  5,  5,  0,  0,\n",
      "         0,  5,  0,  5,  5,  5,  5,  0,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  0,  5,  0,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  0,\n",
      "         5,  5,  5,  0,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  0,  0,  0,  0, 23, 23,\n",
      "        23, 23,  0, 23, 23, 23, 23, 23, 23, 23, 23, 23,  0,  0,  0,  0,  5,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 21, stop: 254, domain accuracy: 0.3717948717948718, not domain accuracy: 0.5215827338129496\n",
      "trueList labels: [0, 23]\n",
      "predictListDomain: [0, 23]\n",
      "predictListNotdomain: [0, 5, 23]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 20 || 253 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 90 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "16/107567\n",
      "[5, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         0,  5,  5,  5,  3,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  0,  5,  0,  5,  5,  5,  5,  5,  5,  0,  0,  5,  5,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0, 59,  0, 59, 59,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  5,  5,  5, 59,  5,  5,  5,  5,  0,  5,\n",
      "         5,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  0,  0,\n",
      "         5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0, 59,  0,  0,  0,  0, 59, 25,  5,  5,  0,  5,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  5,  5,  0,  0,  0,  0,  5,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  5,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0, 59, 59,\n",
      "         0, 59,  0,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  5,  0,  5,  0,  0,  0,  0,  0,  0, 32,  0, 32,  0,  0,\n",
      "         0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  5,  5,  0,  0,  0,  5,  5,  0,\n",
      "         0,  0,  0,  0,  5,  0,  0,  0,  5,  0,  0,  5,  5,  0,  0,  0,  5,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  5], device='cuda:1')\n",
      "start: 1, stop: 212, domain accuracy: 0.3018867924528302, not domain accuracy: 0.8466666666666667\n",
      "trueList labels: [0, 5]\n",
      "predictListDomain: [0, 3, 5]\n",
      "predictListNotdomain: [0, 32, 5, 25, 59]\n",
      "START SITE ACCURATE\n",
      "TRUE START: 0 || 211 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 0 || 35 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "[0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 58, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([ 0, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
      "        58, 58, 58, 58, 58,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 58,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 58,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 58,  0, 58,\n",
      "        58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0, 58,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0], device='cuda:1')\n",
      "start: 12, stop: 134, domain accuracy: 0.10569105691056911, not domain accuracy: 0.9357326478149101\n",
      "trueList labels: [0, 58]\n",
      "predictListDomain: [0, 58]\n",
      "predictListNotdomain: [0, 58]\n",
      "START SITE INACCURATE\n",
      "TRUE START: 11 || 133 :TRUE STOP\n",
      "STOP SITE INACCURATE\n",
      "PRED START: 1 || 22 :PRED STOP\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "18/107567\n"
     ]
    }
   ],
   "source": [
    "masterList = []\n",
    "loopCounter = 0\n",
    "\n",
    "for dataNum in range(0, 20, 2):\n",
    "\n",
    "    torch.cuda.device(gpu_idx)\n",
    "    in_IDS = encoded_test[dataNum:dataNum + 2][\"input_ids\"]\n",
    "    in_IDS = in_IDS.cuda(gpu_idx)\n",
    "    att_mask = encoded_test[dataNum:dataNum + 2][\"attention_mask\"]\n",
    "    att_mask = att_mask.cuda(gpu_idx)\n",
    "    \n",
    "    model = model.cuda(gpu_idx)\n",
    "\n",
    "    preds = model.predict_classes(in_IDS, att_mask, return_logits=True)\n",
    "    #preds = torch.max(preds, 1).indices\n",
    "    # print(preds)\n",
    "    #parses through each validation sample and gets logits and compiles into a masterList of metrics\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    for singleSample in range(len(preds)):\n",
    "\n",
    "    #   ======================  \n",
    "        def labelLabel(labels):\n",
    "            labels = labels.tolist()\n",
    "            trueList = []\n",
    "            print(labels)\n",
    "            previous = 0\n",
    "            for lab in labels:\n",
    "                if lab == -100:\n",
    "                    trueList.append(previous)\n",
    "                else:\n",
    "                    previous = lab\n",
    "                    trueList.append(previous)\n",
    "            return trueList\n",
    "\n",
    "        def domainAcc(true_label, predict):  # finds the start and stop of the actual sequence (range style where stop is actually stop - 1)\n",
    "            switch = False\n",
    "            start = 0\n",
    "            stop = len(true_label)\n",
    "            counter = 1\n",
    "            true_label = true_label\n",
    "            domainLabel = None\n",
    "            numCorrectLabels = 0\n",
    "            numNotLabels = 0\n",
    "\n",
    "\n",
    "            for i in true_label:\n",
    "                if int(i) != 0 and switch == False:\n",
    "                    switch = True\n",
    "                    start = counter\n",
    "                elif int(i) == 0 and switch == True:\n",
    "                    stop = counter - 1\n",
    "                    break\n",
    "                counter += 1\n",
    "\n",
    "            numInDomain = stop - (start - 1)\n",
    "\n",
    "            for i in true_label:\n",
    "                if i != 0:\n",
    "                    domainLabel = i\n",
    "\n",
    "            for i in predict[start - 1:stop]:\n",
    "                if i == domainLabel:\n",
    "                    numCorrectLabels += 1\n",
    "\n",
    "            domainLabelAcc = numCorrectLabels/numInDomain\n",
    "\n",
    "            for i in predict[:start - 1]:\n",
    "                if i == 0:\n",
    "                    numNotLabels += 1\n",
    "\n",
    "            for i in predict[stop - 1:]:\n",
    "                if i == 0:\n",
    "                    numNotLabels += 1\n",
    "\n",
    "            numNotInDomain = len(true_label) - numInDomain\n",
    "            try:\n",
    "                notDomainLabelAcc = numNotLabels/numNotInDomain\n",
    "            except:\n",
    "                notDomainLabelAcc = numNotLabels/len(true_label)\n",
    "\n",
    "            return [start, stop, domainLabelAcc, notDomainLabelAcc]\n",
    "\n",
    "        def evaluate_positions(true, predict):\n",
    "            switch1 = True\n",
    "            switch2 = True\n",
    "            predStart = None\n",
    "            trueStart = None\n",
    "            predStop = None\n",
    "            trueStop = None\n",
    "            counter = 0\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(len(true)):\n",
    "\n",
    "                if true[i] != 0 and switch2:\n",
    "                    switch2 = False\n",
    "                    trueStart = i\n",
    "    #                 print(f\"REAL START POSITION {trueStart}\")\n",
    "\n",
    "                if predict[i] != 0 and switch1:\n",
    "                    switch1 = False\n",
    "                    predStart = i\n",
    "    #                 print(f\"PRED START POSITION {predStart}\")\n",
    "\n",
    "                if true[i] == 0 and switch2 == False:\n",
    "                    switch2 = None\n",
    "                    trueStop = i - 1\n",
    "    #                 print(f\"REAL STOP POSITION {trueStop}\")\n",
    "\n",
    "                if predict[i] == 0 and switch1 == False:\n",
    "                    switch1 = None\n",
    "                    predStop = i - 1\n",
    "    #                 print(f\"PRED STOP POSITION {predStop}\")\n",
    "\n",
    "    #             if predict[i] != true[i]:\n",
    "    #                 print(f\"{counter}) {true[i]}|=|{predict[i]} >> NOT\")\n",
    "    #             else:\n",
    "    #                 print(f\"{counter}) {true[i]}|=|{predict[i]}\")\n",
    "                counter += 1\n",
    "        \n",
    "            if switch2 == False and trueStop == None:\n",
    "                trueStop = len(true)\n",
    "                \n",
    "            if switch1 == False and predStop == None:\n",
    "                predStop = len(pred)\n",
    "                \n",
    "            if trueStart == None and switch2 == True:\n",
    "                print(\"HAAAAAAAAAAAAAAAAAAA NO DOMAIN\")\n",
    "\n",
    "\n",
    "            return (trueStart, trueStop, predStart, predStop)\n",
    "\n",
    "        def matching_labels(true, predict, domainStart, domainStop):\n",
    "            trueList = []\n",
    "            predictListDomain = []\n",
    "            predictListNotdomain = []\n",
    "            predict = predict.tolist()\n",
    "            for label in true:\n",
    "                trueList.append(label)\n",
    "\n",
    "            for label in predict[domainStart:domainStop]:\n",
    "                predictListDomain.append(label)\n",
    "\n",
    "            for label in predict[:domainStart + 1]:\n",
    "                predictListNotdomain.append(label)\n",
    "            for label in predict[domainStop: ]:\n",
    "                predictListNotdomain.append(label)\n",
    "\n",
    "            trueList = set(trueList)\n",
    "            trueList = list(trueList)\n",
    "            predictListDomain = set(predictListDomain)\n",
    "            predictListDomain = list(predictListDomain)\n",
    "            predictListNotdomain = set(predictListNotdomain)\n",
    "            predictListNotdomain = list(predictListNotdomain)\n",
    "\n",
    "            return (trueList, predictListDomain, predictListNotdomain)\n",
    "\n",
    "    #   ======================\n",
    "        fullDataDict = {}\n",
    "        labelDataDict = {}\n",
    "        predict = torch.max(preds[singleSample], 1).indices\n",
    "        true = labelLabel(encoded_test[dataNum + singleSample][\"labels\"])\n",
    "        domainAccuracy = domainAcc(true, predict)\n",
    "        acc_start = domainAccuracy[0]\n",
    "        acc_stop = domainAccuracy[1]\n",
    "        domain_accuracy = domainAccuracy[2]\n",
    "        notDomain_accuracy = domainAccuracy[3]\n",
    "        positions = evaluate_positions(true, predict)\n",
    "        trueStart = positions[0]\n",
    "        trueStop = positions[1]\n",
    "        predStart = positions[2]\n",
    "        predStop = positions[3]\n",
    "        domainStart = acc_start - 1\n",
    "        domainStop = acc_stop\n",
    "        match_label = matching_labels(true, predict, domainStart, domainStop)\n",
    "        labelsInTrue = match_label[0]\n",
    "        labelsInPredDomain = match_label[1]\n",
    "        labelsInPredNotdomain = match_label[2]\n",
    "        start_site = 0\n",
    "        stop_site = 0\n",
    "        attentionLabel = None\n",
    "\n",
    "        for i in labelsInTrue:\n",
    "            if i != 0:\n",
    "                attentionLabel = i\n",
    "        \n",
    "        print(true)\n",
    "        print(predict)\n",
    "        \n",
    "        print(f\"start: {acc_start}, stop: {acc_stop}, domain accuracy: {domain_accuracy}, not domain accuracy: {notDomain_accuracy}\")\n",
    "\n",
    "        print(f\"trueList labels: {labelsInTrue}\")\n",
    "        print(f\"predictListDomain: {labelsInPredDomain}\")\n",
    "        print(f\"predictListNotdomain: {labelsInPredNotdomain}\")\n",
    "\n",
    "        \n",
    "        if trueStart == predStart:\n",
    "            print(f\"START SITE ACCURATE\")\n",
    "            start_site = 1\n",
    "        else:\n",
    "            print(f\"START SITE INACCURATE\")\n",
    "        print(f\"TRUE START: {trueStart} || {trueStop} :TRUE STOP\")\n",
    "        if trueStop == predStop:\n",
    "            print(f\"STOP SITE ACCURATE\")\n",
    "            stop_site = 1\n",
    "        else:\n",
    "            print(f\"STOP SITE INACCURATE\")\n",
    "        print(f\"PRED START: {predStart} || {predStop} :PRED STOP\")\n",
    "\n",
    "        print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "\n",
    "        \"\"\"\n",
    "        1) domain accuracy\n",
    "        2) not domain accuracy\n",
    "        3) start site accuracy\n",
    "        4) stop site accuracy\n",
    "        5) labels in true domain\n",
    "        6) labels in pred domain\n",
    "        7) labels in pred not domain\n",
    "        \"\"\"\n",
    "        fullDataDict[\"domain_accuracy\"] = domain_accuracy\n",
    "        fullDataDict[\"notDomain_accuracy\"] = notDomain_accuracy\n",
    "        fullDataDict[\"start_site\"] = start_site\n",
    "        fullDataDict[\"stop_site\"] = stop_site\n",
    "        fullDataDict[\"trueLabels\"] = labelsInTrue\n",
    "        fullDataDict[\"predDomainLabels\"] = labelsInPredDomain\n",
    "        fullDataDict[\"predNotdomainLabels\"] = labelsInPredNotdomain\n",
    "\n",
    "        labelDataDict[attentionLabel] = fullDataDict\n",
    "        masterList.append(labelDataDict)\n",
    "        \n",
    "        \n",
    "    print(f\"{loopCounter}/{len(encoded_test)}\")\n",
    "    loopCounter += 2\n",
    "    torch.cuda.empty_cache()\n",
    "    \"\"\"\n",
    "    1. check to see if start site matches, and also check if it labelled anything else before start site wrong too\n",
    "    2. check to see if end site matches, also check if it labelled anything else after stop site wrong too\n",
    "    3. check middle to see if it is all filled, also check if its all same label\n",
    "\n",
    "    4. evaluate based on % of correct labels inside of domain\n",
    "    5. also evaluate based on % of correct labels outside of domain\n",
    "\n",
    "    6. then after getting percentages for each sample, evaluate based on the domains (group metrics by domains and average those)\n",
    "    7. see what types of labels are predicted to be inside the domain, and also see what types of labels are predicted to be outisde the domain\n",
    "    \"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parses through masterList to group the metrics of each sample by label for easier evaluation\n",
    "masterEvalDict = {}\n",
    "for labelDictLevel in masterList:\n",
    "    lab = list(labelDictLevel.keys())\n",
    "    lab = lab[0]\n",
    "    labelDict = labelDictLevel[lab]\n",
    "    if lab not in masterEvalDict:\n",
    "        newDict = {\n",
    "            \"domain_accuracy\": [labelDict[\"domain_accuracy\"]],\n",
    "            \"notDomain_accuracy\": [labelDict[\"notDomain_accuracy\"]],\n",
    "            \"start_site\": [labelDict[\"start_site\"]],\n",
    "            \"stop_site\": [labelDict[\"stop_site\"]],\n",
    "            \"trueLabels\": list(labelDict[\"trueLabels\"]),\n",
    "            \"predDomainLabels\": list(labelDict[\"predDomainLabels\"]),\n",
    "            \"predNotdomainLabels\": list(labelDict[\"predNotdomainLabels\"])\n",
    "        }\n",
    "        \n",
    "        masterEvalDict[lab] = newDict\n",
    "    else:\n",
    "        innerLabelDict = masterEvalDict[lab]\n",
    "        innerLabelDict[\"domain_accuracy\"].append(labelDict[\"domain_accuracy\"])\n",
    "        innerLabelDict[\"notDomain_accuracy\"].append(labelDict[\"notDomain_accuracy\"])\n",
    "        innerLabelDict[\"start_site\"].append(labelDict[\"start_site\"])\n",
    "        innerLabelDict[\"stop_site\"].append(labelDict[\"stop_site\"])\n",
    "        \n",
    "        innerLabelDict[\"trueLabels\"] = list(innerLabelDict[\"trueLabels\"])\n",
    "        innerLabelDict[\"trueLabels\"] += labelDict[\"trueLabels\"]\n",
    "        innerLabelDict[\"trueLabels\"] = set(innerLabelDict[\"trueLabels\"])\n",
    "        \n",
    "        innerLabelDict[\"predDomainLabels\"] = list(innerLabelDict[\"predDomainLabels\"])\n",
    "        innerLabelDict[\"predDomainLabels\"] += labelDict[\"predDomainLabels\"]\n",
    "        innerLabelDict[\"predDomainLabels\"] = set(innerLabelDict[\"predDomainLabels\"])\n",
    "        \n",
    "        innerLabelDict[\"predNotdomainLabels\"] = list(innerLabelDict[\"predNotdomainLabels\"])\n",
    "        innerLabelDict[\"predNotdomainLabels\"] += labelDict[\"predNotdomainLabels\"]\n",
    "        innerLabelDict[\"predNotdomainLabels\"] = set(innerLabelDict[\"predNotdomainLabels\"])\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{59: {'domain_accuracy': [0.33783783783783783,\n",
       "   0.43478260869565216,\n",
       "   0.15151515151515152],\n",
       "  'notDomain_accuracy': [0.8105022831050228,\n",
       "   0.8510158013544018,\n",
       "   0.8455114822546973],\n",
       "  'start_site': [0, 0, 0],\n",
       "  'stop_site': [0, 0, 0],\n",
       "  'trueLabels': {0, 59},\n",
       "  'predDomainLabels': {0, 54, 59},\n",
       "  'predNotdomainLabels': {0, 3, 5, 10, 19, 21, 23, 24, 32, 54, 58, 59}},\n",
       " 33: {'domain_accuracy': [0.49504950495049505,\n",
       "   0.3947990543735225,\n",
       "   0.4666666666666667],\n",
       "  'notDomain_accuracy': [0.2857142857142857,\n",
       "   0.7078651685393258,\n",
       "   0.8691588785046729],\n",
       "  'start_site': [0, 0, 0],\n",
       "  'stop_site': [0, 0, 0],\n",
       "  'trueLabels': {0, 33},\n",
       "  'predDomainLabels': {0, 33},\n",
       "  'predNotdomainLabels': {0, 5, 33}},\n",
       " 23: {'domain_accuracy': [0.2517241379310345,\n",
       "   0.34551495016611294,\n",
       "   0.34551495016611294,\n",
       "   0.4304635761589404,\n",
       "   0.3717948717948718],\n",
       "  'notDomain_accuracy': [0.9279279279279279,\n",
       "   0.7061611374407583,\n",
       "   0.6919431279620853,\n",
       "   0.5761904761904761,\n",
       "   0.5215827338129496],\n",
       "  'start_site': [0, 0, 0, 0, 0],\n",
       "  'stop_site': [0, 0, 0, 0, 0],\n",
       "  'trueLabels': {0, 23},\n",
       "  'predDomainLabels': {0, 5, 23},\n",
       "  'predNotdomainLabels': {0, 5, 23}},\n",
       " 2: {'domain_accuracy': [0.3333333333333333],\n",
       "  'notDomain_accuracy': [0.9592760180995475],\n",
       "  'start_site': [0],\n",
       "  'stop_site': [0],\n",
       "  'trueLabels': [0, 2],\n",
       "  'predDomainLabels': [0, 2],\n",
       "  'predNotdomainLabels': [0, 2]},\n",
       " 49: {'domain_accuracy': [0.2549019607843137],\n",
       "  'notDomain_accuracy': [0.7585365853658537],\n",
       "  'start_site': [0],\n",
       "  'stop_site': [0],\n",
       "  'trueLabels': [0, 49],\n",
       "  'predDomainLabels': [0, 49],\n",
       "  'predNotdomainLabels': [0, 49, 23]},\n",
       " 32: {'domain_accuracy': [0.25405405405405407, 0.36666666666666664],\n",
       "  'notDomain_accuracy': [0.5351681957186545, 0.6295180722891566],\n",
       "  'start_site': [0, 0],\n",
       "  'stop_site': [0, 0],\n",
       "  'trueLabels': {0, 32},\n",
       "  'predDomainLabels': {0, 32},\n",
       "  'predNotdomainLabels': {0, 5, 28, 32}},\n",
       " 40: {'domain_accuracy': [0.2777777777777778],\n",
       "  'notDomain_accuracy': [0.7436974789915967],\n",
       "  'start_site': [0],\n",
       "  'stop_site': [0],\n",
       "  'trueLabels': [0, 40],\n",
       "  'predDomainLabels': [40, 0, 54],\n",
       "  'predNotdomainLabels': [0, 40]},\n",
       " 46: {'domain_accuracy': [0.466796875],\n",
       "  'notDomain_accuracy': [0.001953125],\n",
       "  'start_site': [1],\n",
       "  'stop_site': [0],\n",
       "  'trueLabels': [46],\n",
       "  'predDomainLabels': [0, 46],\n",
       "  'predNotdomainLabels': [46]},\n",
       " 39: {'domain_accuracy': [0.20910973084886128],\n",
       "  'notDomain_accuracy': [0.06896551724137931],\n",
       "  'start_site': [0],\n",
       "  'stop_site': [0],\n",
       "  'trueLabels': [0, 39],\n",
       "  'predDomainLabels': [0, 39],\n",
       "  'predNotdomainLabels': [0, 39]},\n",
       " 5: {'domain_accuracy': [0.3018867924528302],\n",
       "  'notDomain_accuracy': [0.8466666666666667],\n",
       "  'start_site': [1],\n",
       "  'stop_site': [0],\n",
       "  'trueLabels': [0, 5],\n",
       "  'predDomainLabels': [0, 3, 5],\n",
       "  'predNotdomainLabels': [0, 32, 5, 25, 59]},\n",
       " 58: {'domain_accuracy': [0.10569105691056911],\n",
       "  'notDomain_accuracy': [0.9357326478149101],\n",
       "  'start_site': [0],\n",
       "  'stop_site': [0],\n",
       "  'trueLabels': [0, 58],\n",
       "  'predDomainLabels': [0, 58],\n",
       "  'predNotdomainLabels': [0, 58]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterEvalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiles the metrics for each label into a label average\n",
    "\n",
    "resultDict = {}\n",
    "for eachLabel in masterEvalDict:\n",
    "    innerLabDict = {}\n",
    "\n",
    "    \n",
    "    metricData = masterEvalDict[eachLabel]\n",
    "    dom_acc = sum(metricData[\"domain_accuracy\"]) / len(metricData[\"domain_accuracy\"])\n",
    "    notDom_acc = sum(metricData[\"notDomain_accuracy\"]) / len(metricData[\"notDomain_accuracy\"])\n",
    "    start_site = sum(metricData[\"start_site\"]) / len(metricData[\"start_site\"])\n",
    "    stop_site = sum(metricData[\"stop_site\"]) / len(metricData[\"stop_site\"])\n",
    "    true_lab = list(metricData[\"trueLabels\"])\n",
    "    predDomLab = list(metricData[\"predDomainLabels\"])\n",
    "    predNotdomLab = list(metricData[\"predNotdomainLabels\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    innerLabDict[\"domain_accuracy\"] = dom_acc\n",
    "    innerLabDict[\"notDomain_accuracy\"] = notDom_acc\n",
    "    innerLabDict[\"start_site\"] = start_site\n",
    "    innerLabDict[\"stop_site\"] = stop_site\n",
    "    innerLabDict[\"true_labels\"] = true_lab\n",
    "    innerLabDict[\"pred_domain_labels\"] = predDomLab\n",
    "    innerLabDict[\"pred_notDomain_labels\"] = predNotdomLab\n",
    "    \n",
    "    resultDict[eachLabel] = innerLabDict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{59: {'domain_accuracy': 0.30804519934954716,\n",
       "  'notDomain_accuracy': 0.8356765222380407,\n",
       "  'start_site': 0.0,\n",
       "  'stop_site': 0.0,\n",
       "  'true_labels': [0, 59],\n",
       "  'pred_domain_labels': [0, 59, 54],\n",
       "  'pred_notDomain_labels': [0, 32, 3, 5, 10, 19, 21, 54, 23, 24, 58, 59]},\n",
       " 33: {'domain_accuracy': 0.45217174199689475,\n",
       "  'notDomain_accuracy': 0.6209127775860948,\n",
       "  'start_site': 0.0,\n",
       "  'stop_site': 0.0,\n",
       "  'true_labels': [0, 33],\n",
       "  'pred_domain_labels': [0, 33],\n",
       "  'pred_notDomain_labels': [0, 33, 5]},\n",
       " 23: {'domain_accuracy': 0.34900249724341453,\n",
       "  'notDomain_accuracy': 0.6847610806668394,\n",
       "  'start_site': 0.0,\n",
       "  'stop_site': 0.0,\n",
       "  'true_labels': [0, 23],\n",
       "  'pred_domain_labels': [0, 5, 23],\n",
       "  'pred_notDomain_labels': [0, 5, 23]},\n",
       " 2: {'domain_accuracy': 0.3333333333333333,\n",
       "  'notDomain_accuracy': 0.9592760180995475,\n",
       "  'start_site': 0.0,\n",
       "  'stop_site': 0.0,\n",
       "  'true_labels': [0, 2],\n",
       "  'pred_domain_labels': [0, 2],\n",
       "  'pred_notDomain_labels': [0, 2]},\n",
       " 49: {'domain_accuracy': 0.2549019607843137,\n",
       "  'notDomain_accuracy': 0.7585365853658537,\n",
       "  'start_site': 0.0,\n",
       "  'stop_site': 0.0,\n",
       "  'true_labels': [0, 49],\n",
       "  'pred_domain_labels': [0, 49],\n",
       "  'pred_notDomain_labels': [0, 49, 23]},\n",
       " 32: {'domain_accuracy': 0.31036036036036035,\n",
       "  'notDomain_accuracy': 0.5823431340039056,\n",
       "  'start_site': 0.0,\n",
       "  'stop_site': 0.0,\n",
       "  'true_labels': [0, 32],\n",
       "  'pred_domain_labels': [32, 0],\n",
       "  'pred_notDomain_labels': [0, 32, 28, 5]},\n",
       " 40: {'domain_accuracy': 0.2777777777777778,\n",
       "  'notDomain_accuracy': 0.7436974789915967,\n",
       "  'start_site': 0.0,\n",
       "  'stop_site': 0.0,\n",
       "  'true_labels': [0, 40],\n",
       "  'pred_domain_labels': [40, 0, 54],\n",
       "  'pred_notDomain_labels': [0, 40]},\n",
       " 46: {'domain_accuracy': 0.466796875,\n",
       "  'notDomain_accuracy': 0.001953125,\n",
       "  'start_site': 1.0,\n",
       "  'stop_site': 0.0,\n",
       "  'true_labels': [46],\n",
       "  'pred_domain_labels': [0, 46],\n",
       "  'pred_notDomain_labels': [46]},\n",
       " 39: {'domain_accuracy': 0.20910973084886128,\n",
       "  'notDomain_accuracy': 0.06896551724137931,\n",
       "  'start_site': 0.0,\n",
       "  'stop_site': 0.0,\n",
       "  'true_labels': [0, 39],\n",
       "  'pred_domain_labels': [0, 39],\n",
       "  'pred_notDomain_labels': [0, 39]},\n",
       " 5: {'domain_accuracy': 0.3018867924528302,\n",
       "  'notDomain_accuracy': 0.8466666666666667,\n",
       "  'start_site': 1.0,\n",
       "  'stop_site': 0.0,\n",
       "  'true_labels': [0, 5],\n",
       "  'pred_domain_labels': [0, 3, 5],\n",
       "  'pred_notDomain_labels': [0, 32, 5, 25, 59]},\n",
       " 58: {'domain_accuracy': 0.10569105691056911,\n",
       "  'notDomain_accuracy': 0.9357326478149101,\n",
       "  'start_site': 0.0,\n",
       "  'stop_site': 0.0,\n",
       "  'true_labels': [0, 58],\n",
       "  'pred_domain_labels': [0, 58],\n",
       "  'pred_notDomain_labels': [0, 58]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "finalZ = {}\n",
    "finalZ[0] = resultDict\n",
    "with open(\"/mnt/storage/grid/home/eric/hmm2bert/pullin_parsed_data/pullin_results_test.json\", \"w\") as file:\n",
    "    json.dump(finalZ, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512, 285])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "we can see by using .size() on the predictions that we get a nested list \n",
    "1. list where each element(list within the list) is one sample from a batch \n",
    "2. list where each element(list within list (512 lists per sample)) is a list of the logits\n",
    "3. list where each element represents a label, for each label, the probability of it being that label is given\n",
    "\n",
    "\"\"\"\n",
    "preds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103,   0, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103, 103, 103, 103,   0,   0, 103, 103, 103,   0, 103, 103, 103,\n",
      "        103, 103,   0, 103, 103, 103, 103, 103,   0, 103, 103,   0,   0,   0,\n",
      "          0,   0, 103,   0,   0,   0, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "        103, 103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 103,\n",
      "          0,   0,   0,   0,   0, 103, 103, 103, 103, 103, 103, 103, 103, 103,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7,   0,\n",
      "          0,   7,   0, 103,   0, 103,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0, 103, 103, 103,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   7,   0,   7,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   7,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0, 103,   0, 103, 103, 103, 103, 103,   0,\n",
      "          0,   0,   0, 262, 262, 262, 262, 262,   7,   7,   7,   7,   7,   7,\n",
      "          7,   7,   7,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0, 262,   0,   0,   0, 262,   0,   0,\n",
      "        262,   0,   0,   0,   0,   7,   0,   0,   0, 262,   0,   0,   0,   0,\n",
      "          0,   0,   7,   7,   0,   7,   0,   0], device='cuda:0') tensor([   0,  103, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    0,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100])\n"
     ]
    }
   ],
   "source": [
    "#shows me the highest prediction probabilities for the labels for 1 sample\n",
    "predict = torch.max(preds[0], 1).indices\n",
    "true = encoded_test[0][\"labels\"]\n",
    "print(predict, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "dnabert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
