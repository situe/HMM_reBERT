{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wnut(file_path):\n",
    "    file_path = Path(file_path)\n",
    "    \n",
    "    raw_text = file_path.read_text().strip()\n",
    "    raw_docs = re.split(r'\\n\\t?\\n', raw_text) #creates a list and splits based on the pattern \\n\\t?\\n which is the newline, tab, newline that comes after every sample sequence\n",
    "    token_docs = []\n",
    "    tag_docs = []\n",
    "    for doc in raw_docs: #iterates over each sample sequence in list\n",
    "        tokens = []\n",
    "        tags = []\n",
    "        for line in doc.split('\\n'): #sequence based on newlines (this breaks it down to each token with its corresponding label per line)\n",
    "            token, tag = line.split('\\t') #splits into a list based on \\t (tab) \n",
    "            tokens.append(token) #adds the new token to tokens list\n",
    "            tags.append(tag) #adds the new tag to tags list (both token and tag have the same index value)\n",
    "        token_docs.append(tokens) #appends the list of tokens in the sequence to masterlist of tokens\n",
    "        tag_docs.append(tags) #appends the list of tags in the sequence to masterlist of tags\n",
    "    return token_docs, tag_docs #returns two lists (filled with lists), one of all tokens, one of all tags where the masterlist contains a list of lists where each inner list contains the tokens/tags for one sequence\n",
    "\n",
    "texts, tags = read_wnut(\"/mnt/storage/grid/home/eric/hmm2bert/example/token_classification_W-NUT/wnut17train.conll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, val_text, train_tags, val_tags = train_test_split(texts, tags, test_size=0.2) #create train-test split\n",
    "\n",
    "unique_tags = set(tag for doc in tags for tag in doc) #nested for loop where for doc in tags, for tag in docs, tag (create a set containing all the unique tags in the masterlist tags)\n",
    "\n",
    "#use to find ID of a certain tag\n",
    "tag2id = {tag: id for id, tag in enumerate(unique_tags)} #enumerate returns a tuple (ID, TAG) so this creates a dict with tags as the key and ID number as the value [for id, tag in enumerate(unique_tags)]\n",
    "\n",
    "#use to find the label for a certain ID\n",
    "id2tag = {id: tag for tag, id in tag2id.items()} #.items() returns a list of tuples (TAG, ID) of the dictionary passed [for tag, id in unique_tags.itmes()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
    "\n",
    "train_encodings = tokenizer(train_text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
    "val_encodings = tokenizer(val_text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "dnabert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
